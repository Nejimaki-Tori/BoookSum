{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('methods')\n",
    "\n",
    "from methods import Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Access_key.txt', 'r', encoding='utf-8') as file:\n",
    "    url, key = file.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = SentenceTransformer('deepvk/USER-bge-m3').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Summarisation(URL=url, KEY=key, model_name='RefalMachine/RuadaptQwen3-32B-Instruct-v2', device=device, encoder=encoder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328262\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "text = \"\\n\".join(bench.collection[97]['text'])\n",
    "chunks = chunk_text(text)\n",
    "print(len(text))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зло под солнцем\n"
     ]
    }
   ],
   "source": [
    "print(bench.collection[97]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1 = await bench.blueprint.run(chunks, mode='cluster', initial_word_limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Краткое содержание \"Веселого Роджера\" Агаты Кристи по заданному плану:**\n",
      "\n",
      "1. **Остров Контрабандистов и взаимосвязь персонажей:** Остров и особняк становятся ареной морального противостояния, где прошлое семьи Маршаллов переплетается с настоящими преступлениями. Изоляция и атмосфера напряженности подчеркивают борьбу силы добра (Пуаро) и зла (Редферны).\n",
      "\n",
      "2. **Капитан Маршалл и его мотивы:** Капитан демонстрирует преданность семье, но его молчание и подозрительность создают барьер для расследования. Эмоциональное отчуждение мешает ему активно участвовать в поиске правды.\n",
      "\n",
      "3. **Курорт и его влияние на гостей:** Преобразование дома в отель обострляет скрытые конфликты среди гостей: ревность, зависть и секреты мешают расследованию. Например, напряженность между миссис Гарднер и мисс Дарнли отражает общую атмосферу недоверия.\n",
      "\n",
      "4. **Пуаро и его метод работы:** Анализ показаний (майор Барри, Эмили Брустер) и проверка временных данных помогают Пуаро выявить ложь. Его логика и понимание психологии связывают отдельные факты в единую картину преступления.\n",
      "\n",
      "5. **Семейные драмы и страхи:** Смерть Арлены разрушает семью Маршаллов: капитан теряет уверенность, Кеннет страдает от ревности к Редферну, Линда скрывает правду. Конфликты иллюстрируют тему утрат доверия и вины.\n",
      "\n",
      "6. **Эмоции и внешняя среда:** Страх, одиночество и месть доминируют в поведении героев. Архитектурные детали особняка и погодные условия усиливают тревогу, контрастируя с видимым благополучием семьи.\n",
      "\n",
      "7. **Тайна \"Солнечного Карниза\":** Место преступления символизирует скрытое зло. Расколотая бутылка здесь указывает на связь убийц с семьей Маршаллов, а пейзаж подчеркивает разрыв между реальностью и иллюзией.\n",
      "\n",
      "8. **Пуаро и его психологический подход:** Изучение финансовых документов Арлены и анализа поведения Редфернов раскрывает их манипуляторские навыки. Логика Пуаро побеждает двойную игру Кристиной и Патрика.\n",
      "\n",
      "9. **Кристина Редферн и ее роль:** Кристина организует убийство Арлены, маскируясь под самоубийство. Мотивы — контроль бизнеса и ликвидация конкурента. Ложные показания и шантаж Линды делают ее главной подозреваемой.\n",
      "\n",
      "10. **Доказательства и мотивы преступлений:** Деньги, бутылка и ножницы подтверждают мошенничество Редфернов. Эти улики связывали их с преступным планом, направленным на обогащение за счет семьи Маршаллов.\n",
      "\n",
      "11. **Исчезновение Арлены Стюарт:** Пропажа Арлены стала катализатором событий, выявившую связи между героями. Это событие усилило подозрения и подтолкнуло к разгадке тайны семьи Маршаллов.\n",
      "\n",
      "12. **Кристина и разрушение лжи:** Попытки Кристины скрыть преступление через фальшивые свидетельства и уничтожение следов оказались тщетными. Ее двойственность делает ее уязвимой перед логикой Пуаро и общественным осуждением.\n",
      "\n",
      "13. **Патрик Редферн и семейные интриги:** Романтическая связь Патрика с Арленой вызвала ревность и амбициозные планы. Союз с Кристиной углубил кризис в семье Маршаллов, создавая основу для новых скандалов.\n",
      "\n",
      "14. **Арлена Маршалл и ее связи:** Арлена оказалась в эпицентре борьбы за наследство и социальный статус, что вызвало зависть и предательство. Ее положение и ошибки прошлого стали триггером для обвинений в адрес окружения.\n",
      "\n",
      "15. **Розамунда Дарнли и стремление к свободе:** Независимость Розамунды вдохновляет другие героини бороться за свободу. Ее решимость уважают даже при угрозе разоблачения.\n",
      "\n",
      "16. **Линда Маршалл и внутренний конфликт:** Противоречия чувств Линды к отцу и другим мужчинам порождают недоверие к ней. Ее эмоциональное состояние осложняет роль свидетельницы и замедляет расследование.\n",
      "\n",
      "17. **Кеннэт Маршалл и его выбор женщин:** Слабость Кеннета привела к зависимости от Кристины, усугубившей кризис в семье. Его решения порождают взаимные обвинения и усугубляют трагедию.\n",
      "\n",
      "18. **Мистер Блант и его роль:** Хотя он мало участвует в действии, присутствие Бланта добавляет таинственности. Его знание истории особняка намекает на глубинные корни преступлений.\n",
      "\n",
      "19. **Легенда о гномах и место преступления:** Мифы о древнем народе придают повествованию мистическую окраску, подчеркивая сложность человеческих помыслов. Символизм места усиливает драматизм финала.\n",
      "\n",
      "20. **Итог расследования Пуаро:** Объединяя улики, психологические портреты и контекст, Пуаро добивается истины, разбив иллюзии. Его триумф разума завершает разоблачение Редфернов и восстановление справедливости.\n"
     ]
    }
   ],
   "source": [
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yagpt5lite\n",
      "99.0058389629703\n",
      "101.04996362898964\n",
      "99.03767797595356\n",
      "Blueprint: 99.70\n",
      "30.353947303025052\n",
      "26.05761333007831\n",
      "25.37439195497427\n",
      "Blueprint cluster: 27.26\n",
      "33.53323245793581\n",
      "34.52723159804009\n",
      "34.45615617907606\n",
      "Hierarchical: 34.17\n",
      "14.063398896949366\n",
      "14.140152772073634\n",
      "14.046449699089862\n",
      "Hierarchical filtered: 14.08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils import chunk_text\n",
    "\n",
    "text = \"\\n\".join(bench.collection[78]['text'])\n",
    "chunks = chunk_text(text)\n",
    "print(len(text))\n",
    "print('chunks: ', len(chunks))\n",
    "\n",
    "model_names = ['RefalMachine/RuadaptQwen3-32B-Instruct-v2', 'DeepSeek V3', 'tpro', 'yagpt5lite']\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    bench.change_model(key, url, name)\n",
    "    a1 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.blueprint.run(chunks, 500, 'default')\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a1 += c\n",
    "    res = a1 / 3\n",
    "    print(f'Blueprint: {res:.2f}')\n",
    "    a2 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.blueprint.run(chunks, 500, 'cluster')\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a2 += c\n",
    "    res = a2 / 3\n",
    "    print(f'Blueprint cluster: {res:.2f}')\n",
    "    a3 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.hierarchical.run(chunks, 500, False)\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a3 += c\n",
    "    res = a3 / 3\n",
    "    print(f'Hierarchical: {res:.2f}')\n",
    "    a4 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.hierarchical.run(chunks, 500, True)\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a4 += c\n",
    "    res = a4 / 3\n",
    "    print(f'Hierarchical filtered: {res:.2f}')\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='tpro', created=None, object=None, owned_by=None, max_model_len=30000, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-32B-Pro-Beta', created=None, object=None, owned_by=None, max_model_len=28000, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-7B-Garant-v2', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-7B-Lite-Beta', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='deepseek-r1-32b', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='qwen32b-coder', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='vikhr12b', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='yagpt5lite', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='qwen3moe30b', created=None, object=None, owned_by=None, max_model_len=28000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen3-32B-Instruct-v1', created=None, object=None, owned_by=None, max_model_len=24000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen3-32B-Instruct-v2', created=None, object=None, owned_by=None, max_model_len=24000, status='offloaded')\n",
      "Model(id='gemma3', created=None, object=None, owned_by=None, max_model_len=22000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-32B-QWQ-Beta', created=None, object=None, owned_by=None, max_model_len=16000, status='offloaded')\n",
      "Model(id='llama3-70b', created=None, object=None, owned_by=None, max_model_len=14000, status='offloaded')\n",
      "Model(id='qwen2.5-72b', created=None, object=None, owned_by=None, max_model_len=14000, status='offloaded')\n",
      "Model(id='DeepSeek V3', created=None, object=None, owned_by=None, max_model_len=-1, status='offloaded')\n",
      "Model(id='Qwen/Qwen2.5-VL-72B-Instruct', created=None, object=None, owned_by=None, max_model_len=-1, status='offloaded')\n",
      "Model(id='Qwen3-235B-A22B', created=None, object=None, owned_by=None, max_model_len=-1, status='offloaded')\n",
      "Model(id='tlite', created=None, object=None, owned_by=None, max_model_len=-1, status='offloaded')\n"
     ]
    }
   ],
   "source": [
    "lst = list(await bench.client.client.models.list())[0][1]\n",
    "for l in lst:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('methods')\n",
    "\n",
    "from methods import Summarisation\n",
    "with open('Access_key.txt', 'r', encoding='utf-8') as file:\n",
    "    url, key = file.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = SentenceTransformer('deepvk/USER-bge-m3').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import chunk_text\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import aiofiles\n",
    "import os\n",
    "import time\n",
    "\n",
    "async def run_bench_for_model(\n",
    "    url: str,\n",
    "    key: str,\n",
    "    model_name: str,\n",
    "    device = None,\n",
    "    encoder = None,\n",
    "    out_dir: str = \"ultra_mega_last_dep_25\",\n",
    "    total = 0, # CHANGE THAT\n",
    "    start_point = 0 # AND THAT TOO\n",
    "):\n",
    "\n",
    "    file_path = f\"{out_dir}/{model_name.replace('/', '_')}.jsonl\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    bench = Summarisation(URL=url, KEY=key, model_name=model_name, device=device, encoder=encoder)\n",
    "    total_count = total\n",
    "    async with aiofiles.open(file_path, \"a\", encoding=\"utf‑8\") as f:\n",
    "        for item in bench.collection[start_point:]:\n",
    "            if total_count == 100:\n",
    "                print('DONE')\n",
    "                break\n",
    "            text = '\\n'.join(item['text'])\n",
    "            if len(text) > 800000:\n",
    "                continue\n",
    "            chunks = chunk_text(text)\n",
    "            s1 = await bench.blueprint.run(chunks, initial_word_limit=500, mode='default')\n",
    "            await f.write(_as_jsonl(model_name, item['title'], item['author'], \"blueprint\", s1))\n",
    "            \n",
    "            s2 = await bench.blueprint.run(chunks, initial_word_limit=500, mode='cluster')\n",
    "            await f.write(_as_jsonl(model_name, item['title'], item['author'], \"blueprint_cluster\", s2))\n",
    "            \n",
    "            s3 = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=False)\n",
    "            await f.write(_as_jsonl(model_name, item['title'], item['author'], \"hierarchical\", s3))\n",
    "            \n",
    "            s4 = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=True)\n",
    "            await f.write(_as_jsonl(model_name, item['title'], item['author'], \"hierarchical_filtered\", s4))\n",
    "            \n",
    "            total_count += 1\n",
    "\n",
    "def _as_jsonl(model, book_title, author, method, annotation):\n",
    "    entry = {\n",
    "        \"ts\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n",
    "        \"model\": model,\n",
    "        \"book_title\": book_title,\n",
    "        \"author\": author,\n",
    "        \"method\": method,\n",
    "        \"annotation\": annotation,\n",
    "    }\n",
    "    return json.dumps(entry, ensure_ascii=False) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AsyncList\n",
    "\n",
    "async def main():\n",
    "    models = AsyncList()\n",
    "    model_names = [\n",
    "        #'RefalMachine/RuadaptQwen3-32B-Instruct-v2'\n",
    "        #'Qwen3-235B-A22B',\n",
    "        #'DeepSeek V3',\n",
    "        #'tpro'\n",
    "        #'RefalMachine/RuadaptQwen2.5-7B-Lite-Beta'\n",
    "        #'yagpt5lite',\n",
    "        'RefalMachine/RuadaptQwen2.5-32B-Pro-Beta'\n",
    "    ]\n",
    "    for name in model_names:\n",
    "        models.append(run_bench_for_model(url, key, name, device, encoder))\n",
    "\n",
    "    await models.complete_couroutines(batch_size=len(model_names))\n",
    "    models = await models.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Summarisation(URL=url, KEY=key, model_name='yagpt5lite', device=device, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = bench.collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('ultra_mega_last_dep_25/yagpt5lite.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = [e['ts'] for e in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее число секунд по категориям:\n",
      "Категория 1: 113.34 секунд (на 100 интервалах)\n",
      "Категория 2: 42.15 секунд (на 100 интервалах)\n",
      "Категория 3: 31.02 секунд (на 100 интервалах)\n",
      "Категория 4: 27.39 секунд (на 100 интервалах)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "timestamps = time_data\n",
    "\n",
    "datetimes = [datetime.fromisoformat(ts) for ts in timestamps]\n",
    "\n",
    "category_cycle = itertools.cycle([1, 2, 3, 4])\n",
    "\n",
    "category_seconds = defaultdict(list)\n",
    "\n",
    "first_diff = timedelta(minutes=2)\n",
    "first_cat = next(category_cycle)\n",
    "category_seconds[first_cat].append(first_diff.total_seconds())\n",
    "\n",
    "for prev, curr in zip(datetimes, datetimes[1:]):\n",
    "    diff = curr - prev\n",
    "    cat = next(category_cycle)\n",
    "    if diff.total_seconds() > 4000: # some results were created in different days\n",
    "        category_seconds[cat].append(2000)\n",
    "        continue\n",
    "    category_seconds[cat].append(diff.total_seconds())\n",
    "\n",
    "print(\"Среднее число секунд по категориям:\")\n",
    "for cat in sorted(category_seconds):\n",
    "    diffs = category_seconds[cat]\n",
    "    avg = sum(diffs) / len(diffs)\n",
    "    print(f\"Категория {cat}: {avg:.2f} секунд (на {len(diffs)} интервалах)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "new_data = []\n",
    "count = 0\n",
    "for i in range(0, 400, 4):\n",
    "    if i + 4 > len(data):\n",
    "        break\n",
    "    while data[i]['book_title'] != collection[count]['title']:\n",
    "            #print(data[i]['book_title'])\n",
    "            #print(collection[count]['title'])\n",
    "        count += 1\n",
    "    tmp = {\n",
    "        'title': data[i]['book_title'], \n",
    "        'author': collection[count]['author'],\n",
    "        'gold_annotation': collection[count]['annotation'],\n",
    "        'annotations': {\n",
    "            'blueprint': data[i]['annotation'],\n",
    "            'blueprint_cluster': data[i + 1]['annotation'],\n",
    "            'hierarchical': data[i + 2]['annotation'],\n",
    "            'hierarchical_filtered': data[i + 3]['annotation']\n",
    "        }\n",
    "    }\n",
    "    new_data.append(tmp)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('RefalMachine_RuadaptQwen3-32B-Instruct-v2.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(new_data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 2621)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruadapt32/RefalMachine_RuadaptQwen3-32B-Instruct-v2.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/boooksum_old/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/boooksum_old/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/boooksum_old/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 2621)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('ruadapt32/RefalMachine_RuadaptQwen3-32B-Instruct-v2.jsonl', 'r', encoding='utf-8') as file:\n",
    "    new_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Башня Волверден\n",
      "Алёша Птицын вырабатывает характер\n",
      "Выбор\n",
      "Апрельское колдовство\n",
      "Будет ласковый дождь\n",
      "И грянул гром\n",
      "Вельд\n",
      "Всё лето в один день\n",
      "Земляничное окошко\n",
      "Аугсбургский меловой круг\n",
      "Все цвета радуги\n",
      "День рождения Алисы\n",
      "Девочка, с которой ничего не случится\n",
      "Антоновские яблоки\n",
      "Грамматика любви\n",
      "Ида\n",
      "Кастрюк\n",
      "Кавказ\n",
      "Князь во князьях\n",
      "В деревне\n",
      "Ворон\n",
      "Золотое дно\n",
      "Агафья\n",
      "Альбом\n",
      "Анюта\n",
      "Белолобый\n",
      "Беззащитное существо\n",
      "Детвора\n",
      "Драма на охоте\n",
      "Горе\n",
      "Гриша\n",
      "Канитель\n",
      "В аптеке\n",
      "Враги\n",
      "Злой мальчик\n",
      "Злоумышленник\n",
      "Короленко в кругу друзей\n",
      "Гувернантка\n",
      "Жгучая тайна\n",
      "Жозеф Фуше\n",
      "Избавилась\n",
      "Возвращение\n",
      "Бобок\n",
      "Денискины рассказы\n",
      "Белая дорога\n",
      "Вакханки\n",
      "Кактус\n",
      "Дым в лесу\n",
      "Голубая чашка\n",
      "Горячий камень\n",
      "Военная тайна\n",
      "Как я мечтал о бескорыстии\n",
      "Браун из Калавераса\n",
      "Джентльмен из Лапорта\n",
      "Король забавляется\n",
      "Дети солнца\n",
      "Егор Булычов и другие\n",
      "В людях\n",
      "Картина\n",
      "Без улыбок\n",
      "Искатель приключений\n",
      "Жизнь Гнора\n",
      "Королевство кривых зеркал\n",
      "Деревянная пастушка\n",
      "Карлик Нос\n",
      "Гедда Габлер\n",
      "Багульник\n",
      "Бамбус\n",
      "Баваклава\n",
      "Верный друг Санчо\n",
      "Всадник, скачущий над городом\n",
      "Девушка-одуванчик\n",
      "Братоубийство\n",
      "В исправительной колонии\n",
      "Дорогие мои мальчишки\n",
      "1408\n",
      "Бабуля\n",
      "Деда\n",
      "Домашние роды\n",
      "Грузовики\n",
      "Иногда они возвращаются\n",
      "Карниз\n",
      "Клацающие зубы\n",
      "Здесь тоже водятся тигры\n",
      "Земляничная весна\n",
      "Вероника решает умереть\n",
      "Дикая охота короля Стаха\n",
      "Восходящее солнце\n",
      "Берег удачи\n",
      "Карибская тайна\n",
      "Карты на стол\n",
      "Врата судьбы\n",
      "Встреча в Багдаде\n",
      "Загадка Ситтафорда\n",
      "Зло под солнцем\n",
      "Гордячка\n",
      "Двенадцатая койка\n",
      "Аль-Исса\n",
      "Барбос и Жулька\n",
      "Гамбринус\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "b = []\n",
    "for item in new_data:\n",
    "    print(item['title'])\n",
    "    tmp_r = []\n",
    "    tmp_b = []\n",
    "    for ann in item['annotations'].values():\n",
    "        tmp_r.append(bench.evaluater.rouge_L(item['gold_annotation'], ann))\n",
    "        tmp_b.append(bench.evaluater.bertscore(item['gold_annotation'], ann))\n",
    "    r.append(tmp_r)\n",
    "    b.append(tmp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"blueprint\",\n",
    "    \"blueprint_cluster\",\n",
    "    \"hierarchical\",\n",
    "    \"hierarchical_filtered\",\n",
    "]\n",
    "\n",
    "row = []\n",
    "for r1, b1 in zip(r, b):\n",
    "    for r2, b2, m in zip(r1, b1, methods):\n",
    "        row.append({\n",
    "            'model': 'yagpt5lite',\n",
    "            'method': m,\n",
    "            'metric': 'rouge-l',\n",
    "            'score': r2 * 100\n",
    "        })\n",
    "        row.append({\n",
    "            'model': 'yagpt5lite',\n",
    "            'method': m,\n",
    "            'metric': 'bertscore',\n",
    "            'score': b2[2] * 100\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = (\n",
    "    df\n",
    "    .groupby([\"model\", \"metric\", \"method\"])\n",
    "    .agg(mean=(\"score\", \"mean\"), std=(\"score\", \"std\"))\n",
    "    .round(3)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tbl = agg.pivot(index=[\"model\",\"metric\"], columns=\"method\", values=\"mean\")\n",
    "std_tbl  = agg.pivot(index=[\"model\",\"metric\"], columns=\"method\", values=\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = mean_tbl.astype(str) + \" ± \" + std_tbl.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[methods]\n",
    "\n",
    "# === 5. Готовим к LaTeX: multiindex → колонки + индекс ===\n",
    "final_df = final.reset_index()\n",
    "# экранируем подчёркивания в названиях\n",
    "final_df.columns = final_df.columns.str.replace(\"_\", r\"\\_\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "yagpt5lite & bertscore & 61.082 ± 3.787 & 61.527 ± 3.256 & 62.485 ± 3.5 & 62.095 ± 3.243 \\\\\n",
      "yagpt5lite & rouge-l & 15.838 ± 5.105 & 14.26 ± 4.422 & 16.874 ± 5.065 & 16.395 ± 4.712 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "RuadaptQwen2.5-7B-Lite-Beta & bertscore & 0.561 ± 0.049 & 0.54 ± 0.04 & 0.554 ± 0.029 & 0.558 ± 0.029 \\\\\n",
      "RuadaptQwen2.5-7B-Lite-Beta & rouge-l & 0.101 ± 0.039 & 0.077 ± 0.028 & 0.086 ± 0.025 & 0.087 ± 0.025 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "RefalMachine_RuadaptQwen3-32B-Instruct-v2 & bertscore & 0.589 ± 0.036 & 0.553 ± 0.033 & 0.573 ± 0.029 & 0.577 ± 0.033 \\\\\n",
      "RefalMachine_RuadaptQwen3-32B-Instruct-v2 & rouge-l & 0.106 ± 0.032 & 0.078 ± 0.021 & 0.11 ± 0.024 & 0.107 ± 0.024 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "bertscore & 0.587 ± 0.038 & 0.577 ± 0.037 & 0.596 ± 0.035 & 0.593 ± 0.034 \\\\\n",
      "rouge-l & 0.141 ± 0.048 & 0.122 ± 0.045 & 0.144 ± 0.043 & 0.138 ± 0.043 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "RefalMachine_RuadaptQwen3-32B-Instruct-v2 & bertscore & 0.569 ± 0.058 & 0.539 ± 0.052 & 0.557 ± 0.034 & 0.557 ± 0.036 \\\\\n",
      "RefalMachine_RuadaptQwen3-32B-Instruct-v2 & rouge-l & 0.104 ± 0.045 & 0.076 ± 0.036 & 0.103 ± 0.029 & 0.1 ± 0.025 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "RefalMachine_RuadaptQwen3-32B-Instruct-v2 & bertscore & 0.589 ± 0.036 & 0.553 ± 0.033 & 0.573 ± 0.029 & 0.577 ± 0.033 \\\\\n",
      "RefalMachine_RuadaptQwen3-32B-Instruct-v2 & rouge-l & 0.106 ± 0.032 & 0.078 ± 0.021 & 0.11 ± 0.024 & 0.107 ± 0.024 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "Qwen3-235B-A22B & bertscore & 0.616 ± 0.033 & 0.593 ± 0.034 & 0.612 ± 0.03 & 0.609 ± 0.027 \\\\\n",
      "Qwen3-235B-A22B & rouge-l & 0.158 ± 0.045 & 0.122 ± 0.036 & 0.149 ± 0.04 & 0.148 ± 0.037 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "DeepSeek V3 & bertscore & 0.58 ± 0.04 & 0.584 ± 0.036 & 0.6 ± 0.031 & 0.6 ± 0.029 \\\\\n",
      "DeepSeek V3 & rouge-l & 0.126 ± 0.046 & 0.112 ± 0.039 & 0.137 ± 0.039 & 0.135 ± 0.037 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "model & Metric & blueprint & blueprint_cluster & hierarchical & hierarchical_filtered \\\\\n",
      "\\midrule\n",
      "tpro & bertscore & 0.59 ± 0.049 & 0.582 ± 0.037 & 0.594 ± 0.03 & 0.595 ± 0.033 \\\\\n",
      "tpro & rouge-l & 0.147 ± 0.049 & 0.118 ± 0.039 & 0.138 ± 0.031 & 0.135 ± 0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# превращаем в DataFrame с нормальными строками\n",
    "final_df = final.reset_index().rename(columns={\"metric\": \"Metric\"})\n",
    "# выводим в LaTeX\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Результаты по методам и моделям}\n",
      "\\label{tab:results_models}\n",
      "\\begin{tabular}{lcccc}\n",
      "\\toprule\n",
      "model & metric & blueprint & blueprint\\_cluster & hierarchical & hierarchical\\_filtered \\\\\n",
      "\\midrule\n",
      "yagpt5lite & bertscore & 0.61 ± 0.036 & 0.614 ± 0.032 & 0.623 ± 0.032 & 0.621 ± 0.033 \\\\\n",
      "yagpt5lite & rouge-l & 0.158 ± 0.052 & 0.14 ± 0.044 & 0.167 ± 0.05 & 0.165 ± 0.047 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = final_df.to_latex(\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    column_format=\"l\" + \"c\"*len(methods),\n",
    "    multicolumn=True,\n",
    "    multirow=True,      # pandas ≥2.1 добавит \\multirow для повторяющихся model\n",
    "    caption=\"Результаты по методам и моделям\",\n",
    "    label=\"tab:results_models\",\n",
    ")\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method         blueprint blueprint_cluster   hierarchical  \\\n",
      "metric                                                      \n",
      "bertscore  0.587 ± 0.038     0.577 ± 0.037  0.596 ± 0.035   \n",
      "rouge-l    0.141 ± 0.048     0.122 ± 0.045  0.144 ± 0.043   \n",
      "\n",
      "method    hierarchical_filtered  \n",
      "metric                           \n",
      "bertscore         0.593 ± 0.034  \n",
      "rouge-l           0.138 ± 0.043  \n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "boooksum_old",
   "language": "python",
   "name": "boooksum_old"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c7064d98a6e46b480c3ade68cc8a3c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d248f79c4cf743e99d35f1af67b15ac7",
      "max": 4836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_757c85b80ca843f08e854ce85650e583",
      "value": 4836
     }
    },
    "16ec219f49aa4847ac8ad49359822eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2026744200244e6aa47a44446ec8a85",
      "placeholder": "​",
      "style": "IPY_MODEL_d36eec2920c3417ba4c8615e2290f49c",
      "value": "README.md: 100%"
     }
    },
    "3e7f31fa3ca247a18b1e3818f6288ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5760f673228a4cf7903d74074a838cc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a7899e5f28c463fa27099a5ea98218d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c47b56edffc4c418ff8ea904697a592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "757c85b80ca843f08e854ce85650e583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88c42a190e6946bd8637a43798ba8c35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e7fb2300a7d44ab84b791feeeb191fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0af4fa6d2f04455af7e7d91cd698a86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a728f73524524bb5942b2cea78eb2345": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a7899e5f28c463fa27099a5ea98218d",
      "placeholder": "​",
      "style": "IPY_MODEL_a0af4fa6d2f04455af7e7d91cd698a86",
      "value": " 1.83k/1.83k [00:00&lt;00:00, 29.5kB/s]"
     }
    },
    "a7857ee187e948d0850a28dd6c7f2242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f22555acc90f463b98f5d47e0a70ba5e",
      "placeholder": "​",
      "style": "IPY_MODEL_88c42a190e6946bd8637a43798ba8c35",
      "value": "librusec_full.py: 100%"
     }
    },
    "a8d4d2c9b0e740fa8e553d587db6592f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae46aa6d346b4fb0adc717855cc84275": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2026744200244e6aa47a44446ec8a85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3f7a153059c461fa83eb81290af2ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7857ee187e948d0850a28dd6c7f2242",
       "IPY_MODEL_0c7064d98a6e46b480c3ade68cc8a3c9",
       "IPY_MODEL_c2b6c403021948598fa7162df4937003"
      ],
      "layout": "IPY_MODEL_9e7fb2300a7d44ab84b791feeeb191fa"
     }
    },
    "c2b6c403021948598fa7162df4937003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5760f673228a4cf7903d74074a838cc1",
      "placeholder": "​",
      "style": "IPY_MODEL_6c47b56edffc4c418ff8ea904697a592",
      "value": " 4.84k/4.84k [00:00&lt;00:00, 76.0kB/s]"
     }
    },
    "d248f79c4cf743e99d35f1af67b15ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36eec2920c3417ba4c8615e2290f49c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e712b923e6614115b54c6b4d36311854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16ec219f49aa4847ac8ad49359822eee",
       "IPY_MODEL_e9cb9d5b314642d7b4a8260978e8d57f",
       "IPY_MODEL_a728f73524524bb5942b2cea78eb2345"
      ],
      "layout": "IPY_MODEL_a8d4d2c9b0e740fa8e553d587db6592f"
     }
    },
    "e9cb9d5b314642d7b4a8260978e8d57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae46aa6d346b4fb0adc717855cc84275",
      "max": 1835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e7f31fa3ca247a18b1e3818f6288ae4",
      "value": 1835
     }
    },
    "f22555acc90f463b98f5d47e0a70ba5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
