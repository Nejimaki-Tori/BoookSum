{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('methods')\n",
    "\n",
    "from methods import Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Access_key.txt', 'r', encoding='utf-8') as file:\n",
    "    url, key = file.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Summarisation(URL=url, KEY=key, model_name='RefalMachine/RuadaptQwen3-32B-Instruct-v2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no_think\n"
     ]
    }
   ],
   "source": [
    "print(bench.blueprint.think_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81049\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "text = \"\\n\".join(bench.collection[78]['text'])\n",
    "chunks = chunk_text(text)\n",
    "print(len(text))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = await bench.blueprint.run(chunks, initial_word_limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Линия Розы: Тайны Времени и Веры\" погружает читателя в масштабное эпическое путешествие, где переплетаются судьбы профессора Роберта Лэнгдона, известного специалиста по символике, и Софии Невё, наследницы древних знаний Приората Сиона, стремящихся раскрыть тайны, скрытые на протяжении веков. Сюжет разворачивается на фоне исторических и религиозных ландшафтов Парижа, Рима и швейцарских гор, ставя перед героями сложные задачи, связанные с разгадкой \"Линии Розы\" — символа, пронизывающего историю от Братства в Иерусалиме до современных интриг в Ватикане и Цюрихе.\n",
      "\n",
      "В центре повествования — Роберт Лэнгдон, недавно восстановивший свою репутацию после громкого скандала, и София Невё, внучка Жака Соньера, несущая в себе наследие Приората. Их союз с Николя Соньером и капитаном Безу Фашем направлен на предотвращение захвата древних знаний епископом \"Опус Деи\" Мануэлем Арингаросой и монахом Сайласом, стремящимися использовать эти знания для усиления своей власти.\n",
      "\n",
      "Действие начинается в роскошных залах Лувра, где шедевры Леонардо да Винчи, включая \"Мона Лизу\" и \"Тайную вечерю\", становятся ключевыми элементами в расшифровке древних шифров, тесно связанных с \"Линией Розы\". По мере развития событий, герои перемещаются из Ватиканских катакомб, где сталкиваются с внутренними конфликтами Арингаросы, предвещающими грядущие изменения, в Цюрих, где встречают Андре Берне, хранителя древних документов, символизирующих глубокие философские трансформации.\n",
      "\n",
      "Путешествие ведет героев через нелинейные временные пласты, возвращаясь к истокам Братства в Иерусалиме, через ордена тамплиеров, раскрывая трагические события 1307 года, и достигая кульминации в соборе Сен-Сюльпис, где происходит ожесточенное противостояние между хранителями и тем, кто стремится скрыть знания. Здесь раскрывается \"la clef de voute\" — ключ, указывающий путь к \"Сангрилу\" — месту, способному радикально изменить основы религии и политики.\n",
      "\n",
      "София, столкнувшись с ожерельем, несущим золотой ключ, открывает путь к \"Сангрилу\", активируя древние легенды и мистические силы. В каждой локации — от Лувра до глубоких катакомб — персонажи сталкиваются с символами, пробуждающими забытые знания, что подчеркивает хрупкость веры и мощь научного поиска.\n",
      "\n",
      "Аннотация завершается мощным аккордом, где каждый выбор героев определяет не только их судьбы, но и будущее веры, напоминая о вечной борьбе между светом и тьмой, знанием и невежеством. \"Линия Розы: Тайны Времени и Веры\" — это не просто расследование, а глубокое философское исследование, где мистика, наука и вера сплетаются в единый узор, призывая к переосмыслению корней христианства и поиску гармонии между прошлым и настоящим. В этом путешествии каждый персонаж, каждое место и каждый символ играют ключевую роль, формируя многогранный портрет эпохи, где истина часто скрывается за фасадом лжи и предательства.\n"
     ]
    }
   ],
   "source": [
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='RefalMachine/RuadaptQwen2.5-7B-Lite-Beta', created=None, object=None, owned_by=None, max_model_len=30000, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-32B-Pro-Beta', created=None, object=None, owned_by=None, max_model_len=28000, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen3-32B-Instruct-v2', created=None, object=None, owned_by=None, max_model_len=24000, status='spawned')\n",
      "Model(id='llama3-70b', created=None, object=None, owned_by=None, max_model_len=14000, status='spawned')\n",
      "Model(id='DeepSeek V3', created=None, object=None, owned_by=None, max_model_len=-1, status='spawned')\n",
      "Model(id='Qwen/Qwen2.5-VL-72B-Instruct', created=None, object=None, owned_by=None, max_model_len=-1, status='spawned')\n",
      "Model(id='Qwen3-235B-A22B', created=None, object=None, owned_by=None, max_model_len=-1, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-7B-Garant-v2', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='deepseek-r1-32b', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='qwen32b-coder', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='tpro', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='vikhr12b', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='yagpt5lite', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='qwen3moe30b', created=None, object=None, owned_by=None, max_model_len=28000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen3-32B-Instruct-v1', created=None, object=None, owned_by=None, max_model_len=24000, status='offloaded')\n",
      "Model(id='gemma3', created=None, object=None, owned_by=None, max_model_len=22000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-32B-QWQ-Beta', created=None, object=None, owned_by=None, max_model_len=16000, status='offloaded')\n",
      "Model(id='qwen2.5-72b', created=None, object=None, owned_by=None, max_model_len=14000, status='offloaded')\n",
      "Model(id='tlite', created=None, object=None, owned_by=None, max_model_len=-1, status='offloaded')\n"
     ]
    }
   ],
   "source": [
    "lst = list(await bench.client.client.models.list())[0][1]\n",
    "for l in lst:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing:   0%|          | 0/100 [17:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     22\u001b[39m chunks = chunk_text(text)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m s = \u001b[38;5;28;01mawait\u001b[39;00m bench.blueprint.run(chunks, initial_word_limit=\u001b[32m500\u001b[39m)\n\u001b[32m     24\u001b[39m tmp[\u001b[33m'\u001b[39m\u001b[33mblueprint\u001b[39m\u001b[33m'\u001b[39m] = s\n\u001b[32m     25\u001b[39m pbar.set_postfix({\n\u001b[32m     26\u001b[39m \u001b[33m'\u001b[39m\u001b[33mblueprint\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(s),\n\u001b[32m     27\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:294\u001b[39m, in \u001b[36mBlueprint.run\u001b[39m\u001b[34m(self, chunks, initial_word_limit)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunks, initial_word_limit=\u001b[32m500\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     s = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_blueprint_summary(chunks, initial_word_limit)\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mself\u001b[39m.clean_memory()\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:279\u001b[39m, in \u001b[36mBlueprint.text_blueprint_summary\u001b[39m\u001b[34m(self, chunks, word_limit)\u001b[39m\n\u001b[32m    276\u001b[39m         tasks.append(\u001b[38;5;28mself\u001b[39m.merge_pair(sum1, sum2, word_limit, blueprint \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m'\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    277\u001b[39m         i = i + \u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i + \u001b[32m1\u001b[39m < \u001b[38;5;28mlen\u001b[39m(summaries) \u001b[38;5;28;01melse\u001b[39;00m i + \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m tasks.complete_couroutines(batch_size=\u001b[32m40\u001b[39m)\n\u001b[32m    280\u001b[39m     summaries = \u001b[38;5;28;01mawait\u001b[39;00m tasks.to_list()\n\u001b[32m    282\u001b[39m final_summary = summaries[\u001b[32m0\u001b[39m].strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\utils.py:118\u001b[39m, in \u001b[36mAsyncList.complete_couroutines\u001b[39m\u001b[34m(self, batch_size)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.couroutine_ids) > \u001b[32m0\u001b[39m:\n\u001b[32m    117\u001b[39m     tasks = [\u001b[38;5;28mself\u001b[39m.contents[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.couroutine_ids[:batch_size]]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     res = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.couroutine_ids, res):\n\u001b[32m    120\u001b[39m         \u001b[38;5;28mself\u001b[39m.contents[i] = r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:248\u001b[39m, in \u001b[36mBlueprint.merge_pair\u001b[39m\u001b[34m(self, sum1, sum2, word_limit, blueprint)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(combo.split()) > word_limit:\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         bp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_single_blueprint(combo)\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    250\u001b[39m         bp = blueprint\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:237\u001b[39m, in \u001b[36mBlueprint.generate_single_blueprint\u001b[39m\u001b[34m(self, chunk)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_single_blueprint\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk): \u001b[38;5;66;03m# для сжатия аннотаций\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     questions = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_questions_chunk(chunk)\n\u001b[32m    238\u001b[39m     answers = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_answer(chunk, questions)\n\u001b[32m    239\u001b[39m     blueprint = \u001b[38;5;28mself\u001b[39m.merge_answers_and_questions([questions], [answers])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:118\u001b[39m, in \u001b[36mBlueprint.generate_questions_chunk\u001b[39m\u001b[34m(self, chunk)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_questions_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk):\n\u001b[32m    116\u001b[39m     myprompt = BLUEPRINT_QUESTIONS_PROMPT.format(chunk=chunk)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     qs = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.get_completion(\n\u001b[32m    119\u001b[39m         myprompt,\n\u001b[32m    120\u001b[39m         max_tokens=\u001b[32m1024\u001b[39m,\n\u001b[32m    121\u001b[39m         rep_penalty=\u001b[32m1.0\u001b[39m\n\u001b[32m    122\u001b[39m     )\n\u001b[32m    124\u001b[39m     questions = extract_response(qs).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m#print(questions)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\utils.py:70\u001b[39m, in \u001b[36mLlmCompleter.get_completion\u001b[39m\u001b[34m(self, query, system, examples, choices, rep_penalty, regex_pattern, max_tokens, use_beam_search, beam_width, answer_prefix)\u001b[39m\n\u001b[32m     53\u001b[39m     beam_width = \u001b[38;5;28mmax\u001b[39m(\u001b[32m3\u001b[39m, beam_width)\n\u001b[32m     54\u001b[39m completion = \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(\n\u001b[32m     55\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.path,\n\u001b[32m     56\u001b[39m     messages=msgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m completion\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:1661\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1620\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1621\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1622\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1658\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1659\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   1660\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1662\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1663\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1664\u001b[39m             {\n\u001b[32m   1665\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   1666\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1667\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   1668\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   1669\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   1670\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   1671\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   1672\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   1673\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   1674\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   1675\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1676\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   1677\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   1678\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1679\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   1680\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   1681\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   1682\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   1683\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1684\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   1685\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1686\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1687\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   1688\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1689\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1690\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1691\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   1692\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1693\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1694\u001b[39m             },\n\u001b[32m   1695\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m   1696\u001b[39m         ),\n\u001b[32m   1697\u001b[39m         options=make_request_options(\n\u001b[32m   1698\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1699\u001b[39m         ),\n\u001b[32m   1700\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   1701\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1702\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   1703\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1843\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1829\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1830\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1831\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1838\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1839\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1840\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1841\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1842\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1537\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1535\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1538\u001b[39m     cast_to=cast_to,\n\u001b[32m   1539\u001b[39m     options=options,\n\u001b[32m   1540\u001b[39m     stream=stream,\n\u001b[32m   1541\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1542\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1543\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1576\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1573\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.custom_auth\n\u001b[32m   1575\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1577\u001b[39m         request,\n\u001b[32m   1578\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1579\u001b[39m         **kwargs,\n\u001b[32m   1580\u001b[39m     )\n\u001b[32m   1581\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1582\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_transports\\default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1249\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\asyncio\\locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def run_benchmark(bench, total_count=100):\n",
    "    final_result = []\n",
    "    count = 0\n",
    "    \n",
    "    pbar = tqdm_asyncio(total=total_count, desc=f'Summarizing ({bench.model_name})', position=0)\n",
    "    \n",
    "    for item in bench.collection:\n",
    "        if count >= total_count:\n",
    "            print('DONE')\n",
    "            break\n",
    "            \n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                \n",
    "                tmp = {}\n",
    "                text = '\\n'.join(item['text'])\n",
    "                if len(text) > 800000:\n",
    "                    break\n",
    "                chunks = chunk_text(text)\n",
    "                s = await bench.blueprint.run(chunks, initial_word_limit=500, mode='default')\n",
    "                tmp['blueprint'] = s\n",
    "                pbar.set_postfix({\n",
    "                'blueprint': len(s),\n",
    "                })\n",
    "                \n",
    "                s = await bench.blueprint.run(chunks, initial_word_limit=500, mode='cluster')\n",
    "                tmp['blueprint_cluster'] = s\n",
    "                pbar.set_postfix({\n",
    "                'blueprint_cluster': len(s),\n",
    "                })\n",
    "                \n",
    "                s = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=False)\n",
    "                tmp['hierarchical'] = s\n",
    "                pbar.set_postfix({\n",
    "                'hierarchical': len(s),\n",
    "                })\n",
    "                \n",
    "                s = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=True)\n",
    "                tmp['hierarchical_filtered'] = s\n",
    "                pbar.set_postfix({\n",
    "                'hierarchical_filtered': len(s),\n",
    "                })\n",
    "                \n",
    "                final_result.append(\n",
    "                    {'title': item['title'], \n",
    "                     'author': item['author'], \n",
    "                     'authors': item['authors'], \n",
    "                     'annotations': tmp, \n",
    "                     'gold_annotation': \n",
    "                     item['annotation']}\n",
    "                )\n",
    "                count += 1\n",
    "                pbar.update(1)\n",
    "                break\n",
    "                \n",
    "            except (KeyboardInterrupt, asyncio.CancelledError):\n",
    "                raise\n",
    "                \n",
    "            except:\n",
    "                await asyncio.sleep(10)\n",
    "                continue\n",
    "                \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AsyncList\n",
    "\n",
    "bench_ruadapt = Summarisation(URL=url, KEY=key, model_name='RefalMachine/RuadaptQwen3-32B-Instruct-v2') \n",
    "bench_deepseek = Summarisation(URL=url, KEY=key, model_name='DeepSeek V3') \n",
    "bench_qwen = Summarisation(URL=url, KEY=key, model_name='Qwen3-235B-A22B')\n",
    "\n",
    "models = AsyncList()\n",
    "\n",
    "models.append(run_benchmark(bench_ruadapt))\n",
    "models.append(run_benchmark(bench_deepseek))\n",
    "model.append(run_benchmark(bench_qwen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_qwen = Summarisation(URL=url, KEY=key, model_name='Qwen3-235B-A22B') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import chunk_text\n",
    "\n",
    "text = \"\\n\".join(bench.collection[78]['text'])\n",
    "chunks = chunk_text(text)\n",
    "print(len(text))\n",
    "print('chunks: ', len(chunks))\n",
    "\n",
    "model_names = ['RefalMachine/RuadaptQwen3-32B-Instruct-v2', 'DeepSeek V3', 'tpro', 'yagpt5lite']\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    bench.change_model(key, url, name)\n",
    "    a1 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.blueprint.run(chunks, 500, 'default')\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a1 += c\n",
    "    res = a1 / 3\n",
    "    print(f'Blueprint: {res:.2f}')\n",
    "    a2 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.blueprint.run(chunks, 500, 'cluster')\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a2 += c\n",
    "    res = a2 / 3\n",
    "    print(f'Blueprint cluster: {res:.2f}')\n",
    "    a3 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.hierarchical.run(chunks, 500, False)\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a3 += c\n",
    "    res = a3 / 3\n",
    "    print(f'Hierarchical: {res:.2f}')\n",
    "    a4 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.hierarchical.run(chunks, 500, True)\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        print(c)\n",
    "        a4 += c\n",
    "    res = a4 / 3\n",
    "    print(f'Hierarchical filtered: {res:.2f}')\n",
    "    print()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "boooksum_old",
   "language": "python",
   "name": "boooksum_old"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c7064d98a6e46b480c3ade68cc8a3c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d248f79c4cf743e99d35f1af67b15ac7",
      "max": 4836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_757c85b80ca843f08e854ce85650e583",
      "value": 4836
     }
    },
    "16ec219f49aa4847ac8ad49359822eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2026744200244e6aa47a44446ec8a85",
      "placeholder": "​",
      "style": "IPY_MODEL_d36eec2920c3417ba4c8615e2290f49c",
      "value": "README.md: 100%"
     }
    },
    "3e7f31fa3ca247a18b1e3818f6288ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5760f673228a4cf7903d74074a838cc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a7899e5f28c463fa27099a5ea98218d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c47b56edffc4c418ff8ea904697a592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "757c85b80ca843f08e854ce85650e583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88c42a190e6946bd8637a43798ba8c35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e7fb2300a7d44ab84b791feeeb191fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0af4fa6d2f04455af7e7d91cd698a86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a728f73524524bb5942b2cea78eb2345": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a7899e5f28c463fa27099a5ea98218d",
      "placeholder": "​",
      "style": "IPY_MODEL_a0af4fa6d2f04455af7e7d91cd698a86",
      "value": " 1.83k/1.83k [00:00&lt;00:00, 29.5kB/s]"
     }
    },
    "a7857ee187e948d0850a28dd6c7f2242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f22555acc90f463b98f5d47e0a70ba5e",
      "placeholder": "​",
      "style": "IPY_MODEL_88c42a190e6946bd8637a43798ba8c35",
      "value": "librusec_full.py: 100%"
     }
    },
    "a8d4d2c9b0e740fa8e553d587db6592f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae46aa6d346b4fb0adc717855cc84275": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2026744200244e6aa47a44446ec8a85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3f7a153059c461fa83eb81290af2ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7857ee187e948d0850a28dd6c7f2242",
       "IPY_MODEL_0c7064d98a6e46b480c3ade68cc8a3c9",
       "IPY_MODEL_c2b6c403021948598fa7162df4937003"
      ],
      "layout": "IPY_MODEL_9e7fb2300a7d44ab84b791feeeb191fa"
     }
    },
    "c2b6c403021948598fa7162df4937003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5760f673228a4cf7903d74074a838cc1",
      "placeholder": "​",
      "style": "IPY_MODEL_6c47b56edffc4c418ff8ea904697a592",
      "value": " 4.84k/4.84k [00:00&lt;00:00, 76.0kB/s]"
     }
    },
    "d248f79c4cf743e99d35f1af67b15ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36eec2920c3417ba4c8615e2290f49c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e712b923e6614115b54c6b4d36311854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16ec219f49aa4847ac8ad49359822eee",
       "IPY_MODEL_e9cb9d5b314642d7b4a8260978e8d57f",
       "IPY_MODEL_a728f73524524bb5942b2cea78eb2345"
      ],
      "layout": "IPY_MODEL_a8d4d2c9b0e740fa8e553d587db6592f"
     }
    },
    "e9cb9d5b314642d7b4a8260978e8d57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae46aa6d346b4fb0adc717855cc84275",
      "max": 1835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e7f31fa3ca247a18b1e3818f6288ae4",
      "value": 1835
     }
    },
    "f22555acc90f463b98f5d47e0a70ba5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
