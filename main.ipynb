{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRIBvsK3a--A",
    "outputId": "28fc983a-07b3-4adc-c340-f8f5a6b03299"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 496858/496858 [4:05:20<00:00, 33.75it/s, found=634]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "def similarity(a: str, b: str) -> float:\n",
    "    emb_1 = encoder.encode(a)\n",
    "    emb_2 = encoder.encode(b)\n",
    "\n",
    "    return round(float(encoder.similarity(emb_1, emb_2).item()), 3)\n",
    "\n",
    "dataset = load_dataset('IlyaGusev/librusec_full', split='train', streaming=True)\n",
    "\n",
    "with open('All_annotations.json', 'r', encoding='utf-8') as f:\n",
    "    all_a = json.load(f)\n",
    "\n",
    "with open('titles.json', 'r', encoding='utf-8') as f:\n",
    "    needed_titles = json.load(f)\n",
    "    \n",
    "annotations_dict = {}\n",
    "for a in all_a:\n",
    "    annotations_dict[a['title']] = a\n",
    "     \n",
    "SIM_TH = 0.65\n",
    "texts_dict = {}\n",
    "needed_titles = set(needed_titles)\n",
    "encoder = SentenceTransformer('deepvk/USER-bge-m3')\n",
    "\n",
    "with tqdm(total=496858, desc=\"Processing records\") as pbar:\n",
    "    for record in dataset:\n",
    "        title = record.get(\"title\", \"\")\n",
    "        authors = record.get(\"authors\", [\"\"])\n",
    "        lang = record.get(\"lang\", \"\")\n",
    "\n",
    "        if title in needed_titles:\n",
    "            if title not in texts_dict:\n",
    "                if lang in ['ru', 'rus']:\n",
    "                    if annotations_dict[title]['author'] in authors:\n",
    "                        texts_dict[title] = (record.get(\"sections\", \"\"), authors)\n",
    "                    else:\n",
    "                        for author in authors:\n",
    "                            if similarity(author, annotations_dict[title]['author']) > SIM_TH:\n",
    "                                texts_dict[title] = (record.get(\"sections\", \" \"), authors)\n",
    "                                break\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'found': len(texts_dict),\n",
    "        })\n",
    "        pbar.update(1)\n",
    "\n",
    "        if len(texts_dict) == len(needed_titles):\n",
    "            break\n",
    "            \n",
    "combined = []\n",
    "for title, value in texts_dict.items():\n",
    "  combined.append({'title': title, 'author': annotations_dict[title]['author'], 'authors': value[1], 'annotation': annotations_dict[title]['annotation'],'text': value[0], 'categories': annotations_dict[title]['categories']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('methods')\n",
    "\n",
    "from methods import Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Access_key.txt', 'r', encoding='utf-8') as file:\n",
    "    url, key = file.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Summarisation(URL=url, KEY=key, model_name='RefalMachine/RuadaptQwen3-32B-Instruct-v2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.change_model(key, url, 'RefalMachine/RuadaptQwen2.5-7B-Lite-Beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no_think\n"
     ]
    }
   ],
   "source": [
    "print(bench.blueprint.think_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek V3\n"
     ]
    }
   ],
   "source": [
    "print(bench.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='RefalMachine/RuadaptQwen2.5-7B-Lite-Beta', created=None, object=None, owned_by=None, max_model_len=30000, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-32B-Pro-Beta', created=None, object=None, owned_by=None, max_model_len=28000, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen3-32B-Instruct-v2', created=None, object=None, owned_by=None, max_model_len=24000, status='spawned')\n",
      "Model(id='llama3-70b', created=None, object=None, owned_by=None, max_model_len=14000, status='spawned')\n",
      "Model(id='DeepSeek V3', created=None, object=None, owned_by=None, max_model_len=-1, status='spawned')\n",
      "Model(id='Qwen/Qwen2.5-VL-72B-Instruct', created=None, object=None, owned_by=None, max_model_len=-1, status='spawned')\n",
      "Model(id='Qwen3-235B-A22B', created=None, object=None, owned_by=None, max_model_len=-1, status='spawned')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-7B-Garant-v2', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='deepseek-r1-32b', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='qwen32b-coder', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='tpro', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='vikhr12b', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='yagpt5lite', created=None, object=None, owned_by=None, max_model_len=30000, status='offloaded')\n",
      "Model(id='qwen3moe30b', created=None, object=None, owned_by=None, max_model_len=28000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen3-32B-Instruct-v1', created=None, object=None, owned_by=None, max_model_len=24000, status='offloaded')\n",
      "Model(id='gemma3', created=None, object=None, owned_by=None, max_model_len=22000, status='offloaded')\n",
      "Model(id='RefalMachine/RuadaptQwen2.5-32B-QWQ-Beta', created=None, object=None, owned_by=None, max_model_len=16000, status='offloaded')\n",
      "Model(id='qwen2.5-72b', created=None, object=None, owned_by=None, max_model_len=14000, status='offloaded')\n",
      "Model(id='tlite', created=None, object=None, owned_by=None, max_model_len=-1, status='offloaded')\n"
     ]
    }
   ],
   "source": [
    "lst = list(await bench.client.client.models.list())[0][1]\n",
    "for l in lst:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 60664\n",
      "1 60300\n",
      "2 635480\n",
      "3 870892\n",
      "4 17631\n",
      "5 12383\n",
      "6 24864\n",
      "7 24373\n",
      "8 10304\n",
      "9 18493\n",
      "10 25151\n",
      "11 47887\n",
      "12 122565\n",
      "13 44215\n",
      "14 28251\n",
      "15 17376\n",
      "16 16603\n",
      "17 16872\n",
      "18 7772\n",
      "19 17818\n",
      "20 11862\n",
      "21 11645\n",
      "22 11566\n",
      "23 18891\n",
      "24 3825\n",
      "25 7398\n",
      "26 9984\n",
      "27 8546\n",
      "28 9307\n",
      "29 335612\n",
      "30 9789\n",
      "31 5568\n",
      "32 3927\n",
      "33 7307\n",
      "34 25253\n",
      "35 4284\n",
      "36 6688\n",
      "37 60183\n",
      "38 25868\n",
      "39 117459\n",
      "40 483063\n",
      "41 9877\n",
      "42 9501\n",
      "43 29465\n",
      "44 411489\n",
      "45 7646\n",
      "46 83778\n",
      "47 1537853\n",
      "48 18316\n",
      "49 37593\n",
      "50 43823\n",
      "51 8217\n",
      "52 192441\n",
      "53 932304\n",
      "54 11062\n",
      "55 21920\n",
      "56 24449\n",
      "57 102817\n",
      "58 135059\n",
      "59 82998\n",
      "60 524475\n",
      "61 705631\n",
      "62 63766\n",
      "63 49239\n",
      "64 66981\n",
      "65 121975\n",
      "66 698463\n",
      "67 52643\n",
      "68 133309\n",
      "69 14779\n",
      "70 18277\n",
      "71 37638\n",
      "72 157543\n",
      "73 17064\n",
      "74 26297\n",
      "75 3840\n",
      "76 56724\n",
      "77 253915\n",
      "78 81049\n",
      "79 53921\n",
      "80 24017\n",
      "81 55174\n",
      "82 30742\n",
      "83 51644\n",
      "84 35035\n",
      "85 59239\n",
      "86 7965\n",
      "87 18731\n",
      "88 286982\n",
      "89 365070\n",
      "90 592985\n",
      "91 345999\n",
      "92 291264\n",
      "93 351626\n",
      "94 363080\n",
      "95 313399\n",
      "96 334280\n",
      "97 328262\n",
      "98 169556\n",
      "99 24202\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(bench.collection[:100]):\n",
    "    print(i, len('\\n'.join(j['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "60664\n",
      "chunks:  8\n",
      "1\n",
      "60300\n",
      "chunks:  9\n",
      "2\n",
      "635480\n",
      "chunks:  86\n",
      "3\n",
      "870892\n",
      "chunks:  109\n",
      "4\n",
      "17631\n",
      "chunks:  3\n",
      "5\n",
      "12383\n",
      "chunks:  2\n",
      "6\n",
      "24864\n",
      "chunks:  4\n",
      "7\n",
      "24373\n",
      "chunks:  4\n",
      "8\n",
      "10304\n",
      "chunks:  2\n",
      "9\n",
      "18493\n",
      "chunks:  3\n",
      "10\n",
      "25151\n",
      "chunks:  4\n",
      "11\n",
      "47887\n",
      "chunks:  7\n",
      "12\n",
      "122565\n",
      "chunks:  17\n",
      "13\n",
      "44215\n",
      "chunks:  6\n",
      "14\n",
      "28251\n",
      "chunks:  5\n",
      "15\n",
      "17376\n",
      "chunks:  3\n",
      "16\n",
      "16603\n",
      "chunks:  3\n",
      "17\n",
      "16872\n",
      "chunks:  3\n",
      "18\n",
      "7772\n",
      "chunks:  2\n",
      "19\n",
      "17818\n",
      "chunks:  3\n",
      "20\n",
      "11862\n",
      "chunks:  2\n",
      "21\n",
      "11645\n",
      "chunks:  2\n",
      "22\n",
      "11566\n",
      "chunks:  2\n",
      "23\n",
      "18891\n",
      "chunks:  3\n",
      "24\n",
      "3825\n",
      "chunks:  1\n",
      "25\n",
      "7398\n",
      "chunks:  2\n",
      "26\n",
      "9984\n",
      "chunks:  2\n",
      "27\n",
      "8546\n",
      "chunks:  2\n",
      "28\n",
      "9307\n",
      "chunks:  2\n",
      "29\n",
      "335612\n",
      "chunks:  48\n",
      "30\n",
      "9789\n",
      "chunks:  2\n",
      "31\n",
      "5568\n",
      "chunks:  1\n",
      "32\n",
      "3927\n",
      "chunks:  1\n",
      "33\n",
      "7307\n",
      "chunks:  2\n",
      "34\n",
      "25253\n",
      "chunks:  4\n",
      "35\n",
      "4284\n",
      "chunks:  1\n",
      "36\n",
      "6688\n",
      "chunks:  2\n",
      "37\n",
      "60183\n",
      "chunks:  8\n",
      "38\n",
      "25868\n",
      "chunks:  4\n",
      "39\n",
      "117459\n",
      "chunks:  16\n",
      "40\n",
      "483063\n",
      "chunks:  56\n",
      "41\n",
      "9877\n",
      "chunks:  2\n",
      "42\n",
      "9501\n",
      "chunks:  2\n",
      "43\n",
      "29465\n",
      "chunks:  5\n",
      "44\n",
      "411489\n",
      "chunks:  61\n",
      "45\n",
      "7646\n",
      "chunks:  2\n",
      "46\n",
      "83778\n",
      "chunks:  12\n",
      "47\n",
      "1537853\n",
      "chunks:  197\n",
      "48\n",
      "18316\n",
      "chunks:  3\n",
      "49\n",
      "37593\n",
      "chunks:  6\n",
      "50\n",
      "43823\n",
      "chunks:  7\n",
      "51\n",
      "8217\n",
      "chunks:  2\n",
      "52\n",
      "192441\n",
      "chunks:  28\n",
      "53\n",
      "932304\n",
      "chunks:  131\n",
      "54\n",
      "11062\n",
      "chunks:  2\n",
      "55\n",
      "21920\n",
      "chunks:  3\n",
      "56\n",
      "24449\n",
      "chunks:  4\n",
      "57\n",
      "102817\n",
      "chunks:  16\n",
      "58\n",
      "135059\n",
      "chunks:  24\n",
      "59\n",
      "82998\n",
      "chunks:  16\n",
      "60\n",
      "524475\n",
      "chunks:  77\n",
      "61\n",
      "705631\n",
      "chunks:  95\n",
      "62\n",
      "63766\n",
      "chunks:  9\n",
      "63\n",
      "49239\n",
      "chunks:  7\n",
      "64\n",
      "66981\n",
      "chunks:  10\n",
      "65\n",
      "121975\n",
      "chunks:  18\n",
      "66\n",
      "698463\n",
      "chunks:  89\n",
      "67\n",
      "52643\n",
      "chunks:  7\n",
      "68\n",
      "133309\n",
      "chunks:  22\n",
      "69\n",
      "14779\n",
      "chunks:  3\n",
      "70\n",
      "18277\n",
      "chunks:  3\n",
      "71\n",
      "37638\n",
      "chunks:  6\n",
      "72\n",
      "157543\n",
      "chunks:  22\n",
      "73\n",
      "17064\n",
      "chunks:  3\n",
      "74\n",
      "26297\n",
      "chunks:  4\n",
      "75\n",
      "3840\n",
      "chunks:  1\n",
      "76\n",
      "56724\n",
      "chunks:  7\n",
      "77\n",
      "253915\n",
      "chunks:  37\n",
      "78\n",
      "81049\n",
      "chunks:  11\n",
      "79\n",
      "53921\n",
      "chunks:  8\n",
      "80\n",
      "24017\n",
      "chunks:  4\n",
      "81\n",
      "55174\n",
      "chunks:  8\n",
      "82\n",
      "30742\n",
      "chunks:  5\n",
      "83\n",
      "51644\n",
      "chunks:  8\n",
      "84\n",
      "35035\n",
      "chunks:  5\n",
      "85\n",
      "59239\n",
      "chunks:  9\n",
      "86\n",
      "7965\n",
      "chunks:  2\n",
      "87\n",
      "18731\n",
      "chunks:  3\n",
      "88\n",
      "286982\n",
      "chunks:  35\n",
      "89\n",
      "365070\n",
      "chunks:  51\n",
      "90\n",
      "592985\n",
      "chunks:  80\n",
      "91\n",
      "345999\n",
      "chunks:  47\n",
      "92\n",
      "291264\n",
      "chunks:  40\n",
      "93\n",
      "351626\n",
      "chunks:  46\n",
      "94\n",
      "363080\n",
      "chunks:  50\n",
      "95\n",
      "313399\n",
      "chunks:  41\n",
      "96\n",
      "334280\n",
      "chunks:  45\n",
      "97\n",
      "328262\n",
      "chunks:  43\n",
      "98\n",
      "169556\n",
      "chunks:  24\n",
      "99\n",
      "24202\n",
      "chunks:  4\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "\n",
    "for i, item in enumerate(bench.collection[:100]):\n",
    "    text = \"\\n\".join(item['text'])\n",
    "    chunks = chunk_text(text)\n",
    "    print(i)\n",
    "    print(len(text))\n",
    "    print('chunks: ', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81049\n",
      "chunks:  11\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "\n",
    "text = \"\\n\".join(bench.collection[78]['text'])\n",
    "chunks = chunk_text(text)\n",
    "print(len(text))\n",
    "print('chunks: ', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['RefalMachine/RuadaptQwen3-32B-Instruct-v2', 'DeepSeek V3', 'tpro', 'yagpt5lite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RefalMachine/RuadaptQwen3-32B-Instruct-v2\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m      8\u001b[39m     start = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     s = \u001b[38;5;28;01mawait\u001b[39;00m bench.blueprint.run(chunks, \u001b[32m500\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m     end = time.perf_counter()\n\u001b[32m     11\u001b[39m     c = end - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:295\u001b[39m, in \u001b[36mBlueprint.run\u001b[39m\u001b[34m(self, chunks, initial_word_limit, mode)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunks, initial_word_limit=\u001b[32m500\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode = mode\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     s = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_blueprint_summary(chunks, initial_word_limit)\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.clean_memory()\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:279\u001b[39m, in \u001b[36mBlueprint.text_blueprint_summary\u001b[39m\u001b[34m(self, chunks, word_limit)\u001b[39m\n\u001b[32m    276\u001b[39m         tasks.append(\u001b[38;5;28mself\u001b[39m.merge_pair(sum1, sum2, word_limit, blueprint \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m'\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    277\u001b[39m         i = i + \u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i + \u001b[32m1\u001b[39m < \u001b[38;5;28mlen\u001b[39m(summaries) \u001b[38;5;28;01melse\u001b[39;00m i + \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m tasks.complete_couroutines(batch_size=\u001b[32m40\u001b[39m)\n\u001b[32m    280\u001b[39m     summaries = \u001b[38;5;28;01mawait\u001b[39;00m tasks.to_list()\n\u001b[32m    282\u001b[39m final_summary = summaries[\u001b[32m0\u001b[39m].strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\utils.py:118\u001b[39m, in \u001b[36mAsyncList.complete_couroutines\u001b[39m\u001b[34m(self, batch_size)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.couroutine_ids) > \u001b[32m0\u001b[39m:\n\u001b[32m    117\u001b[39m     tasks = [\u001b[38;5;28mself\u001b[39m.contents[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.couroutine_ids[:batch_size]]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     res = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.couroutine_ids, res):\n\u001b[32m    120\u001b[39m         \u001b[38;5;28mself\u001b[39m.contents[i] = r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:251\u001b[39m, in \u001b[36mBlueprint.merge_pair\u001b[39m\u001b[34m(self, sum1, sum2, word_limit, blueprint)\u001b[39m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    250\u001b[39m         bp = blueprint\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     combo = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.summarize_with_blueprint(combo, bp)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m combo\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:105\u001b[39m, in \u001b[36mBlueprint.summarize_with_blueprint\u001b[39m\u001b[34m(self, chunk, blueprint)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     myprompt = SUMMARIZE_BLUEPRINT_NO_ANSWERS_PROMPT.format(blueprint=blueprint, chunk=chunk)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m sumry = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.get_completion(\n\u001b[32m    106\u001b[39m     myprompt,\n\u001b[32m    107\u001b[39m     max_tokens=\u001b[32m2048\u001b[39m,\n\u001b[32m    108\u001b[39m     rep_penalty=\u001b[32m1.0\u001b[39m\n\u001b[32m    109\u001b[39m )\n\u001b[32m    111\u001b[39m summary = extract_response(sumry)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m summary\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\utils.py:70\u001b[39m, in \u001b[36mLlmCompleter.get_completion\u001b[39m\u001b[34m(self, query, system, examples, choices, rep_penalty, regex_pattern, max_tokens, use_beam_search, beam_width, answer_prefix)\u001b[39m\n\u001b[32m     53\u001b[39m     beam_width = \u001b[38;5;28mmax\u001b[39m(\u001b[32m3\u001b[39m, beam_width)\n\u001b[32m     54\u001b[39m completion = \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(\n\u001b[32m     55\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.path,\n\u001b[32m     56\u001b[39m     messages=msgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m completion\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:1661\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1620\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1621\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1622\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1658\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1659\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   1660\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1662\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1663\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1664\u001b[39m             {\n\u001b[32m   1665\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   1666\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1667\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   1668\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   1669\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   1670\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   1671\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   1672\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   1673\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   1674\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   1675\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1676\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   1677\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   1678\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1679\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   1680\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   1681\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   1682\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   1683\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1684\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   1685\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1686\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1687\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   1688\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1689\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1690\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1691\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   1692\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1693\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1694\u001b[39m             },\n\u001b[32m   1695\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m   1696\u001b[39m         ),\n\u001b[32m   1697\u001b[39m         options=make_request_options(\n\u001b[32m   1698\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1699\u001b[39m         ),\n\u001b[32m   1700\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   1701\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1702\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   1703\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1843\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1829\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1830\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1831\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1838\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1839\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1840\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1841\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1842\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1537\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1535\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1538\u001b[39m     cast_to=cast_to,\n\u001b[32m   1539\u001b[39m     options=options,\n\u001b[32m   1540\u001b[39m     stream=stream,\n\u001b[32m   1541\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1542\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1543\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1576\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1573\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.custom_auth\n\u001b[32m   1575\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1577\u001b[39m         request,\n\u001b[32m   1578\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1579\u001b[39m         **kwargs,\n\u001b[32m   1580\u001b[39m     )\n\u001b[32m   1581\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1582\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_transports\\default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1249\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\asyncio\\locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    bench.change_model(key, url, name)\n",
    "    a1 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.blueprint.run(chunks, 500, 'default')\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        a1 += c\n",
    "    res = a1 / 3\n",
    "    print(f'Blueprint: {res:.2f}')\n",
    "    a2 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.blueprint.run(chunks, 500, 'cluster')\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        a2 += c\n",
    "    res = a2 / 3\n",
    "    print(f'Blueprint cluster: {res:.2f}')\n",
    "    a3 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.hierarchical.run(chunks, 500, False)\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        a3 += c\n",
    "    res = a3 / 3\n",
    "    print(f'Hierarchical: {res:.2f}')\n",
    "    a4 = 0\n",
    "    for _ in range(3):\n",
    "        start = time.perf_counter()\n",
    "        s = await bench.hierarchical.run(chunks, 500, True)\n",
    "        end = time.perf_counter()\n",
    "        c = end - start\n",
    "        a4 += c\n",
    "    res = a4 / 3\n",
    "    print(f'Hierarchical filtered: {res:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.change_model(key, url, 'RefalMachine/RuadaptQwen3-32B-Instruct-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.change_model(key, url, 'DeepSeek V3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.change_model(key, url, 'tpro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.change_model(key, url, 'yagpt5lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.change_model(key, url, 'RefalMachine/RuadaptQwen2.5-7B-Lite-Beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint: 96.89\n",
      "Blueprint: 107.47\n",
      "Blueprint: 106.65\n",
      "103.66953063333374\n"
     ]
    }
   ],
   "source": [
    "a1 = 0\n",
    "for _ in range(3):\n",
    "    start = time.perf_counter()\n",
    "    s = await bench.blueprint.run(chunks, 500, 'default')\n",
    "    end = time.perf_counter()\n",
    "    c = end - start\n",
    "    a1 += c\n",
    "    print(f'Blueprint: {c:.2f}')\n",
    "print(a1 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint cluster: 74.62\n",
      "Blueprint cluster: 88.15\n",
      "Blueprint cluster: 74.21\n",
      "78.99428309999955\n"
     ]
    }
   ],
   "source": [
    "a2 = 0\n",
    "for _ in range(3):\n",
    "    start = time.perf_counter()\n",
    "    s = await bench.blueprint.run(chunks, 500, 'cluster')\n",
    "    end = time.perf_counter()\n",
    "    c = end - start\n",
    "    a2 += c\n",
    "    print(f'Blueprint cluster: {c:.2f}')\n",
    "print(a2 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical: 85.62\n",
      "Hierarchical: 77.69\n",
      "Hierarchical: 90.60\n",
      "84.63721289999982\n"
     ]
    }
   ],
   "source": [
    "a3 = 0\n",
    "for _ in range(3):\n",
    "    start = time.perf_counter()\n",
    "    s = await bench.hierarchical.run(chunks, 500, False)\n",
    "    end = time.perf_counter()\n",
    "    c = end - start\n",
    "    a3 += c\n",
    "    print(f'Hierarchical: {c:.2f}')\n",
    "print(a3 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical filtered: 24.76\n",
      "Hierarchical filtered: 26.49\n",
      "Hierarchical filtered: 25.86\n",
      "25.702083133333264\n"
     ]
    }
   ],
   "source": [
    "a4 = 0\n",
    "for _ in range(3):\n",
    "    start = time.perf_counter()\n",
    "    s = await bench.hierarchical.run(chunks, 500, True)\n",
    "    end = time.perf_counter()\n",
    "    c = end - start\n",
    "    a4 += c\n",
    "    print(f'Hierarchical filtered: {c:.2f}')\n",
    "print(a4 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Краткое содержание:\n",
      "\n",
      "**Эмоциональные реакции Мейзи:**\n",
      "- Мейзи испытывает смесь восторга от красоты и магии Волвердена, особенно восхищаясь елизаветинской архитектурой, но испытывает глубокий страх и беспокойство перед башней и старушкой Бесси, что отражает её недоверие к мистическим аспектам и предчувствие надвигающейся опасности.\n",
      "\n",
      "**Характеристики Волвердена:**\n",
      "- Замок, совмещающий готические и елизаветинские элементы, символизирует защиту и магическую силу, защищённый трёхслойной магией и древними символами, что подчеркивает его мистическую значимость и древнее наследие.\n",
      "\n",
      "**Значение старухи Бесси:**\n",
      "- Старуха Бесси, хранительница древних знаний, играет ключевую роль в местной мифологии, её присутствие в башне Волвердена усиливает мистическую атмосферу, вызывая одновременно страх и глубокое уважение среди обитателей, будучи связующей нитью с прошлым Братства.\n",
      "\n",
      "**Развитие событий и переживаний Мейзи:**\n",
      "- Путь Мейзи от первоначального восторга к глубокому посвящению в Братство включает сложные испытания, встречи с таинственными персонажами и погружение в мистические ритуалы, включая Наречение Мертвых, что ускоряет её духовное развитие и понимание мистических глубин Волвердена.\n",
      "\n",
      "**Персонажи и их особенности:**\n",
      "- Мейзи, выделяющаяся своей чувствительностью и любознательностью, становится центральным персонажем, в то время как Бесси и миссис Уэст, каждая со своими уникальными магическими навыками, оказывают значительное влияние на её восприятие и эволюцию, формируя её как потенциального лидера Братства.\n",
      "\n",
      "**Магия и ритуалы:**\n",
      "- Элементы магии, такие как \"живые картины\", мелодичная музыка, сложные ритуалы и даже символические жертвоприношения, глубоко связаны с темами смерти и возрождения, подчеркивая цикличность жизни и мистические трансформации, укрепляя мистическую непрерывность Братства.\n",
      "\n",
      "**Изменения крипты и персонажей:**\n",
      "- Мейзи адаптируется к таинственной крипте, её восприятие пространства претерпевает глубокую трансформацию, наполненную мистическими откровениями, укрепляя её связь с историей и магией Волвердена. Взаимодействия среди персонажей обостряются, особенно вокруг Бесси, отражая борьбу между традициями и новыми взглядами на магию.\n",
      "\n",
      "**Обрушения зданий и символика:**\n",
      "- Символические и реальные разрушения, включая обрушение башни, отражают внутренние напряжения и нестабильность, вызванную приходом новых сил и разрушением устаревших структур, символизируя очистительные и трансформационные процессы, необходимые для возрождения магической мощи Братства.\n",
      "\n",
      "**Заключение:**\n",
      "Текст погружает читателя в многогранный мистический мир Волвердена, где Мейзи, пройдя через испытания и мистические открытия, достигает посвящения в Братство, раскрывая не только тайны древнего замка, но и глубинные аспекты собственной души, акцентируя цикличность бытия и неизбежность духовных метаморфоз, укрепляя веру в вечное возрождение магических традиций.\n"
     ]
    }
   ],
   "source": [
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В начале XX века, в живописных окрестностях кентского Вильде, где каждый камень хранит древние тайны, разворачивается история, связанная с таинственным замком Волверден, недавно обретшим второе дыхание благодаря стараниям его нового хозяина – полковника Уэст. Этот величественный особняк, где архитектура эпохи Елизаветы изящно переплетается с изысканными элементами, становится не просто жилищем, а живым зеркалом столетий, окутанным легендами и мистикой.\n",
      "\n",
      "В центр повествования попадает Мейзи Льюэллин, дочь антиквара, чья глубокая связь с прошлым и страстью к антиквариату словно магнит притягивает её к Волвердену. Приезд Мейзи в замок, организованный заботливой миссис Уэст, хозяйкой, преданной традициям и хранительницей старинного очага, знаменует начало её погружения в атмосферу, насыщенную предчувствием и мистикой.\n",
      "\n",
      "С первых шагов Мейзи увлекает реставрация замка, особенно таинственная башня, символизирующая не столько физическую реконструкцию, сколько попытку сохранить хрупкие нити прошлого. Встреча с загадочной Старухой Бесси, обитательницей церковного погоста, открывает перед ней древние легенды и пророчествa, тесно связанные с судьбой Волвердена, усиливая мистическую насыщенность его стен.\n",
      "\n",
      "Кульминацией становится рождественский вечер, наполненный магией и предчувствием. Исполнительница баллады \"Недотрога - Мейзи\" Иоланта, вместе с её сестрой Геддой, приглашёнными на праздник, своими выступлениями и откровениями о предопределении судьбы погружают обитателей замка в глубину мистических связей. Эти события не только усиливают напряжение, но и ставят Мейзи перед сложным выбором между прошлым, хранящим тайны, и будущим, полным неизведанных возможностей.\n",
      "\n",
      "Антагонизм истории не столько во внешних конфликтах, сколько в внутреннем противостоянии с неизбежностью перемен, в стремлении сохранить память о прошлом. Через переживания Мейзи раскрывается универсальная тема утраты и стремления к вечному, где каждый элемент замка, от древних скульптур до шепотов Бесси, становится символом глубоких, почти мифологических связей времен.\n",
      "\n",
      "Ночной разговор с Иолантой и Геддой знаменует важный поворот в жизни героини, предвещая начало значительных трансформаций не только в её собственной судьбе, но и в судьбе самого Волвердена. Завершая рассказ, читатель остаётся в ожидании дальнейших событий, где границы между реальным и сверхъестественным становятся ещё более тонкими, предвещая сложные испытания и неожиданные откровения, в которых переплетаются нити судьбы, памяти и надежды на возрождение. Таким образом, Волверден предстаёт не просто как место, но как живое существо, дышащее легендами, где каждый новый день приносит новые тайны и возможности для тех, кто отважится их раскрыть.\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Кто является главной героиней истории и куда она приглашена перед Рождеством?', 'Какова история башни Волверден и почему ее пришлось реконструировать?', 'Кто такая старуха Бесси и что она рассказывает Мэйзи о башне Волверден?', 'Кто такие две загадочные девушки, которых Мэйзи встречает на ужине, и что они представляют собой?', 'Что происходит с Мэйзи, когда она идет на прогулку с подругами и попадает в склеп?', 'Какова цель ритуала, в котором Мэйзи становится участницей, и что ожидается от нее?', 'Кто спасает Мэйзи от участи стать третьей жертвой и что происходит с башней Волверден в конце истории?']\n",
      "\n",
      "\n",
      "['Двадцатилетняя дочь антиквара Мэйзи Льюэллин приглашена погостить в замок елизаветинской эпохи Волверден-холл в окрестностях Лондона перед Рождеством.', 'Башня Волверден была старинной башней, которая, согласно легенде, была трижды скреплена и укреплена душами девушек, чтобы противостоять натиску людей и дьявола. Однако со временем башня пришла в плачевное состояние и ее пришлось реконструировать, чтобы она не рухнула. Согласно пророчеству старой Бесси, перестроенная башня все равно упадет. И действительно, после событий, связанных с Мэйзи, башня была разрушена ударом молнии во время грозы, что было воспринято как исполнение пророчества.', 'Старуха Бесси - своеобразная личность, которую слуги боятся и считают ведьмой с дурным глазом. Она рассказывает Мэйзи легенду о башне Волверден, которая была трижды скреплена и укреплена душами девушек, чтобы противостоять натиску людей и дьявола. Она пророчит, что перестроенная башня все равно упадет. Бесси также знает множество страшных историй о церкви Волверден, но самое худшее в том, что эти истории - чистая правда. Позже она повторяет, что угадала в Мэйзи третью жертву, и погибает под обломками обрушившейся башни.', 'Две загадочные девушки, которых Мэйзи встречает на ужине, — Иоланта и Гедда. Они представляют собой две предыдущие жертвы, замурованные заживо много лет назад в башне Волверден, и являются частью мистического и сверхъестественного мира, связанного с башней и ритуалами, которые там происходят. Они появляются перед Мэйзи как красивые и обаятельные девушки, но на самом деле являются призраками или духами, связанными с башней и играющими ключевую роль в ритуале, в который вовлекается Мэйзи.', 'Когда Мэйзи идет на прогулку с подругами и попадает в склеп, она попадает под их очарование и начинает понимать язык мертвых. Её ведут к трону Верховного жреца, где она узнает, что должна стать третьей жертвой для защиты башни Волверден. Несмотря на первоначальный страх, Мэйзи соглашается стать жертвой, но позже, когда они выходят из склепа, она осознает, что была одурманена и пытается сопротивляться. Однако подруги продолжают вести её к башне, где она почти становится жертвой, но её спасает оксфордский студент.', 'Цель ритуала - завершение древнего обряда, связанного со строительством башни Волверден, который требует трех жертв для укрепления постройки. От Мэйзи ожидается, что она станет третьей жертвой, добровольно бросившись вниз с башни, чтобы защитить ее от молнии и выполнить вековой ритуал.', 'Мэйзи спасает оксфордский студент, который оттягивает её назад, когда она собирается броситься вниз с башни. В конце истории башня Волверден разрушается после удара молнии, под обломками погибает старая Бесси. Мэйзи остаётся жива, но её опыт и воспоминания о событиях в башне остаются для неё травмирующими и непонятыми другими.']\n",
      "\n",
      "\n",
      "['Главной героиней истории является Мейзи Льюэллин, дочь антиквара. Она приглашена в замок Волверден перед Рождеством, где становится участницей событий, наполненных магией и предчувствием.', 'История башни Волверден не раскрыта в аннотации в полной мере, но упоминается, что она является частью реставрации замка, проводимой под руководством полковника Уэста. Башня символизирует не столько физическую реконструкцию, сколько попытку сохранить хрупкие нити прошлого. Её реконструкция является важной частью усилий по возрождению и сохранению Волвердена, но конкретные причины, по которым она потребовала реконструкции, не указаны в предоставленной аннотации.', 'Старуха Бесси - обитательница церковного погоста, которая рассказывает Мейзи древние легенды и пророчества, тесно связанные с судьбой Волвердена, усиливая мистическую насыщенность его стен.', 'Две загадочные девушки, которых Мэйзи встречает на ужине, - это Иоланта и Гедда, исполнительницы баллады \"Недотрога - Мейзи\". Они представляют собой мистическую и художественную связь с прошлым и судьбой, своими выступлениями и откровениями о предопределении судьбы погружая обитателей замка в глубину мистических связей.', 'В аннотации нет информации о том, что Мэйзи идет на прогулку с подругами и попадает в склеп.', 'Цель ритуала, в котором Мэйзи становится участницей, не прямо указана в аннотации, но можно сделать вывод, что он связан с мистическими и пророческими событиями, разворачивающимися в замке Волверден. Ритуал, вероятно, направлен на сохранение памяти о прошлом и усиление мистических связей между обитателями замка и его стенами. От Мэйзи ожидается, что она примет участие в этом ритуале и, возможно, сыграет ключевую роль в сохранении или раскрытии тайн Волвердена, что может быть связано с её глубокой связью с прошлым и страстью к антиквариату.', 'Аннотация не содержит информации о том, что Мэйзи спасают от участи стать третьей жертвой, или о том, что происходит с башней Волверден в конце истории. Предоставленная информация фокусируется на атмосфере, мистике и внутренних конфликтах персонажей, но не раскрывает конкретных деталей о спасении Мэйзи или окончательной судьбе башни.']\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((np.float32(0.64318556), np.float32(0.54767674), np.float32(0.59160113)),\n",
       " 0.4393,\n",
       " 0.2857142857142857,\n",
       " 0.2365714285714286)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await bench.evaluater.evaluate_annotation(bench.collection[0]['annotation'], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Кто является главной героиней истории и куда она приглашена перед Рождеством?', 'Какова история старинной башни Волверден и почему её пришлось реконструировать?', 'Кто такая старуха Бесси и что она рассказывает Мэйзи о башне Волверден?', 'Что происходит с Мэйзи во время ужина и живых картин в замке Волверден-холл?', 'Кто такие Иоланта и Гедда, и как они появляются в жизни Мэйзи?', 'Что происходит с Мэйзи, когда она идет на прогулку с Иолантой и Геддой, и куда они ее ведут?', 'Что такое Братство Мёртвых Зодчих и Жертв пределов Волвердена, и какова их роль в истории?', 'Почему Мэйзи соглашается стать третьей жертвой, и что происходит с ней на верхней площадке башни?', 'Кто спасает Мэйзи от жертвы, и что происходит с ней после этого?', 'Что происходит с башней Волверден в конце истории, и как Мэйзи реагирует на это событие?']\n",
      "\n",
      "\n",
      "['Двадцатилетняя дочь антиквара Мэйзи Льюэллин приглашена погостить в замок елизаветинской эпохи Волверден-холл в окрестностях Лондона перед Рождеством.', 'Старинная башня Волверден имела славную историю, но была в плачевном состоянии и требовала реконструкции, чтобы не рухнуть. Согласно легенде, башня была трижды скреплена и укреплена душами девушек, чтобы противостоять натиску людей и дьявола. Однако, несмотря на реконструкцию, башня в конечном итоге обрушилась после удара молнии, унеся с собой жизнь старой Бесси.', 'Старуха Бесси - своеобразная личность, которую слуги боятся и считают ведьмой с дурным глазом. Она рассказывает Мэйзи легенду о башне Волверден, которая была трижды скреплена и укреплена душами девушек, чтобы противостоять натиску людей и дьявола. Она пророчит, что перестроенная башня все равно упадет. Также Бесси знает множество страшных историй о церкви Волверден, но самое худшее в том, что эти истории - чистая правда. Позже она повторяет, что угадала в Мэйзи третью жертву, и погибает под обломками обрушившейся башни.', 'Во время ужина и живых картин в замке Волверден-холл Мэйзи надевает белое платье-ампир и участвует в живых картинах, которые посвящены смерти и античным мистическим сюжетам. Её это немного печалит. На сцене она замечает двух прелестных девушек в струящихся нарядах, но сидящий рядом оксфордский студент их не видит и странно косится на Мэйзи. Девушки спускаются в зал, садятся рядом с Мэйзи, начинают с ней беседовать, и та испытывает к ним мгновенную симпатию. Мэйзи расстраивает, что все картины печальны, но девушки уверяют её, что не нужно страшиться врат смерти, ведь жизнь так суетна и коротка. Подруги цитируют надпись на вратах церкви Волвердена: «Смерть — врата к жизни». После представления миссис Уэст сетует, что Мэйзи всё время сидела одна, и на её рассказ о двух красивых подругах хозяйка только удивляется, поскольку кроме девушки их никто не видел.', 'Иоланта и Гедда - две загадочные и красивые девушки, которые появляются в жизни Мэйзи во время её пребывания в замке Волверден-холл. Они отличаются не только красотой и безупречным сложением, но и обладают неким не поддающимся определению очарованием. Мэйзи испытывает к ним мгновенную симпатию и духовную близость. Однако, как выясняется позже, Иоланта и Гедда - это две предыдущие жертвы, замурованные заживо много лет назад, и они привлекают Мэйзи в свой мир, чтобы она стала третьей жертвой для укрепления башни Волверден. Они появляются перед Мэйзи как живые люди, но на самом деле являются тенями или духами, связанными с башней и её темной историей.', 'Когда Мэйзи идет на прогулку с Иолантой и Геддой, они ведут ее через кладбище к башне Волверден. Подруги не оставляют следов на снегу, и они приглашают Мэйзи в гости в склеп, где они живут. Мэйзи спускается по лестнице, и подруги держат ее за руки, внушая ей полное доверие. В склепе Мэйзи попадает в красивый просторный зал, выстроенный в восточном стиле, где она встречает теней и становится участницей ритуала, в котором она должна стать третьей жертвой для укрепления башни.', 'Братство Мёртвых Зодчих и Жертв пределов Волвердена — это группа теней, которые, согласно истории, являются душами тех, кто строил и на ком строили в освящённом веками месте Волверден-холла. Они играют ключевую роль в истории, поскольку являются участниками векового ритуала, требующего три жертвы для укрепления башни. Две предыдущие жертвы, Иоланта и Гедда, уже являются частью этого братства, а Мэйзи должна стать третьей жертвой. Братство ожидает Мэйзи, и они оживляются при её появлении, ожидая её участия в ритуале. Жрец объясняет, что все тени башни — это Братство Мёртвых Зодчих и Жертв, и что Мэйзи предназначена стать одной из них.', 'Мэйзи соглашается стать третьей жертвой в состоянии исступленного экстаза, под влиянием своих подруг-жертв, Иоланты и Гедды, которые обещают не оставлять её до самого конца. На верхней площадке башни Мэйзи впадает в панику, но Иоланта обнимает её и уговаривает броситься вниз. Однако в последний момент её останавливает оксфордский студент, который оттягивает её назад и спасает от гибели.', 'Мэйзи спасает оксфордский студент, который оттягивает её назад, когда она собирается броситься вниз с башни. После этого её сносят вниз, приносят в спальню, укладывают в постель, и она некоторое время лежит без сознания. Когда она приходит в себя, у её постели — врач и миссис Уэст, которые уверяют, что она ходила в лунатическом припадке и чуть не свалилась с башни. Они не верят её рассказам о жертвах, тенях и жреце, считая, что всё это было лишь страшным сном. Однако Мэйзи вскоре узнаёт, что башня действительно обрушилась, поражённая молнией во время ночной грозы, и под обломками погибла старая Бесси. Мэйзи остаётся в отчаянии, считая себя виновной в обрушении башни, но её никто не понимает.', 'В конце истории башня Волверден разрушается после удара молнии. Мэйзи, увидев разрушение башни, реагирует с ужасом и отчаянием, утверждая, что она виновата в обрушении башни, хотя никто не понимает ее слов, считая, что она просто испытала страшный сон или лунатический припадок.']\n",
      "\n",
      "\n",
      "['Мейзи является главной героиней истории, и она приглашена в Волверден перед Рождеством.', 'История старинной башни Волверден глубоко связана с мистическим наследием и древними традициями Братства. Башня, как часть замка Волверден, была не только архитектурным элементом, но и символом защиты и магической силы, защищённым трёхслойной магией и древними символами. Однако, со временем, башня стала символом внутренних напряжений и нестабильности, вызванной приходом новых сил и разрушением устаревших структур. Её обрушение можно рассматривать как символическое отражение необходимости очистительных и трансформационных процессов, необходимых для возрождения магической мощи Братства. Реконструкция башни, таким образом, стала необходимым шагом в процессе обновления и укрепления мистических традиций Братства, а также в контексте личностного роста и духовного развития Мейзи, которая прошла через сложные испытания и мистические открытия, чтобы достичь посвящения в Братство.', 'Старуха Бесси — хранительница древних знаний, играющая ключевую роль в местной мифологии. Она усиливает мистическую атмосферу в башне Волвердена, вызывая одновременно страх и глубокое уважение среди обитателей. Однако аннотация не содержит конкретной информации о том, что она рассказывает Мэйзи о башне Волверден.', 'Во время ужина и живых картин в замке Волверден-холл Мэйзи испытывает глубокое чувство удивления и восхищения, наблюдая за магическими элементами, такими как \"живые картины\" и мелодичная музыка, что усиливает её связь с мистической атмосферой Волвердена и способствует её духовному развитию и пониманию мистических глубин замка.', 'В предоставленной аннотации нет упоминания о персонажах Иоланте и Гедде.', 'Аннотация не содержит информации о прогулке Мейзи с Иолантой и Геддой, поэтому невозможно определить, куда они её ведут или что происходит во время этой прогулки.', 'Братство Мёртвых Зодчих и Жертв пределов Волвердена представляет собой мистическую организацию, глубоко связанную с древними традициями и магическими практиками. Их роль в истории заключается в сохранении и развитии мистических знаний, а также в обеспечении непрерывности магических традиций. Братство, возглавляемое фигурами như старуха Бесси и миссис Уэст, играет ключевую роль в духовном развитии Мейзи, вводя её в тайны Волвердена и мистические ритуалы, такие как Наречение Мертвых. Через свои действия и взаимодействия члены Братства способствуют трансформации Мейзи в потенциального лидера, а также влияют на эволюцию мистических сил и традиций внутри Волвердена.', 'Мэйзи соглашается стать третьей жертвой, потому что она глубоко связана с мистическими энергиями Волвердена и чувствует необходимость принять участие в ритуале, который, по её мнению, поможет ей понять и соединиться с магией места на более глубоком уровне. На верхней площадке башни Мэйзи проходит через трансформирующий опыт, который включает в себя символическое жертвоприношение и мистическое откровение, позволяющее ей постичь суть магии и тайны Братства. Этот опыт становится поворотным моментом в её духовном развитии и понимании мистических глубин Волвердена.', 'Аннотация не содержит информации о том, кто спасает Мэйзи от жертвы, и что происходит с ней после этого.', 'Башня Волверден обрушается, символизируя очистительные и трансформационные процессы, необходимые для возрождения магической мощи Братства. Мейзи, пройдя через сложные испытания и мистические открытия, достигает посвящения в Братство, раскрывая не только тайны древнего замка, но и глубинные аспекты собственной души. Это событие становится частью её духовного развития и понимания мистических глубин Волвердена, укрепляя её связь с историей и магией Волвердена.']\n",
      "\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((np.float32(0.6147925), np.float32(0.51682734), np.float32(0.56156945)),\n",
       " 0.3215,\n",
       " 0.1,\n",
       " 0.06949999999999999)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await bench.evaluater.evaluate_annotation(bench.collection[0]['annotation'], s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint\n",
      "((np.float32(0.65899706), np.float32(0.5885342), np.float32(0.62177575)), 0.4988, 0.5714285714285714, 0.454)\n",
      "Cluster blueprint\n",
      "((np.float32(0.62056816), np.float32(0.53078747), np.float32(0.57217735)), 0.3997, 0.1111111111111111, 0.081)\n",
      "Hierarchical\n",
      "((np.float32(0.6443127), np.float32(0.55432045), np.float32(0.59593827)), 0.4336, 0.5714285714285714, 0.43842857142857145)\n",
      "Hierarchical filtered\n",
      "((np.float32(0.6438272), np.float32(0.55141735), np.float32(0.59404993)), 0.4317, 0.5714285714285714, 0.441)\n",
      "Blueprint\n",
      "((np.float32(0.57740545), np.float32(0.5320905), np.float32(0.5538226)), 0.2276, 0.2727272727272727, 0.1969090909090909)\n",
      "Cluster blueprint\n",
      "((np.float32(0.54771286), np.float32(0.49291065), np.float32(0.51886874)), 0.3262, 0.18181818181818182, 0.12854545454545455)\n",
      "Hierarchical\n",
      "((np.float32(0.56958234), np.float32(0.4970916), np.float32(0.5308737)), 0.3647, 0.1, 0.09290000000000001)\n",
      "Hierarchical filtered\n",
      "((np.float32(0.5903005), np.float32(0.51581717), np.float32(0.55055106)), 0.3247, 0.2, 0.1693)\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "\n",
    "for item in bench.collection[:2]:\n",
    "    text = '\\n'.join(item['text'])\n",
    "    chunks = chunk_text(text)\n",
    "    s = await bench.blueprint.run(chunks, initial_word_limit=500)\n",
    "    print('Blueprint')\n",
    "    print(await bench.evaluater.evaluate_annotation(item['annotation'], s))\n",
    "    s = await bench.cluster_blueprint.run(chunks, initial_word_limit=500)\n",
    "    print('Cluster blueprint')\n",
    "    print(await bench.evaluater.evaluate_annotation(item['annotation'], s))\n",
    "    s = await bench.hierarchical.run(chunks, initial_word_limit=500)\n",
    "    print('Hierarchical')\n",
    "    print(await bench.evaluater.evaluate_annotation(item['annotation'], s))\n",
    "    s = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=True)\n",
    "    print('Hierarchical filtered')\n",
    "    print(await bench.evaluater.evaluate_annotation(item['annotation'], s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing:   0%|          | 0/100 [17:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     22\u001b[39m chunks = chunk_text(text)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m s = \u001b[38;5;28;01mawait\u001b[39;00m bench.blueprint.run(chunks, initial_word_limit=\u001b[32m500\u001b[39m)\n\u001b[32m     24\u001b[39m tmp[\u001b[33m'\u001b[39m\u001b[33mblueprint\u001b[39m\u001b[33m'\u001b[39m] = s\n\u001b[32m     25\u001b[39m pbar.set_postfix({\n\u001b[32m     26\u001b[39m \u001b[33m'\u001b[39m\u001b[33mblueprint\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(s),\n\u001b[32m     27\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:294\u001b[39m, in \u001b[36mBlueprint.run\u001b[39m\u001b[34m(self, chunks, initial_word_limit)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunks, initial_word_limit=\u001b[32m500\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     s = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_blueprint_summary(chunks, initial_word_limit)\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mself\u001b[39m.clean_memory()\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:279\u001b[39m, in \u001b[36mBlueprint.text_blueprint_summary\u001b[39m\u001b[34m(self, chunks, word_limit)\u001b[39m\n\u001b[32m    276\u001b[39m         tasks.append(\u001b[38;5;28mself\u001b[39m.merge_pair(sum1, sum2, word_limit, blueprint \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m'\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    277\u001b[39m         i = i + \u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i + \u001b[32m1\u001b[39m < \u001b[38;5;28mlen\u001b[39m(summaries) \u001b[38;5;28;01melse\u001b[39;00m i + \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m tasks.complete_couroutines(batch_size=\u001b[32m40\u001b[39m)\n\u001b[32m    280\u001b[39m     summaries = \u001b[38;5;28;01mawait\u001b[39;00m tasks.to_list()\n\u001b[32m    282\u001b[39m final_summary = summaries[\u001b[32m0\u001b[39m].strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\utils.py:118\u001b[39m, in \u001b[36mAsyncList.complete_couroutines\u001b[39m\u001b[34m(self, batch_size)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.couroutine_ids) > \u001b[32m0\u001b[39m:\n\u001b[32m    117\u001b[39m     tasks = [\u001b[38;5;28mself\u001b[39m.contents[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.couroutine_ids[:batch_size]]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     res = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.couroutine_ids, res):\n\u001b[32m    120\u001b[39m         \u001b[38;5;28mself\u001b[39m.contents[i] = r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:248\u001b[39m, in \u001b[36mBlueprint.merge_pair\u001b[39m\u001b[34m(self, sum1, sum2, word_limit, blueprint)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(combo.split()) > word_limit:\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         bp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_single_blueprint(combo)\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    250\u001b[39m         bp = blueprint\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:237\u001b[39m, in \u001b[36mBlueprint.generate_single_blueprint\u001b[39m\u001b[34m(self, chunk)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_single_blueprint\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk): \u001b[38;5;66;03m# для сжатия аннотаций\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     questions = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_questions_chunk(chunk)\n\u001b[32m    238\u001b[39m     answers = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_answer(chunk, questions)\n\u001b[32m    239\u001b[39m     blueprint = \u001b[38;5;28mself\u001b[39m.merge_answers_and_questions([questions], [answers])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\methods\\blueprint.py:118\u001b[39m, in \u001b[36mBlueprint.generate_questions_chunk\u001b[39m\u001b[34m(self, chunk)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_questions_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk):\n\u001b[32m    116\u001b[39m     myprompt = BLUEPRINT_QUESTIONS_PROMPT.format(chunk=chunk)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     qs = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.get_completion(\n\u001b[32m    119\u001b[39m         myprompt,\n\u001b[32m    120\u001b[39m         max_tokens=\u001b[32m1024\u001b[39m,\n\u001b[32m    121\u001b[39m         rep_penalty=\u001b[32m1.0\u001b[39m\n\u001b[32m    122\u001b[39m     )\n\u001b[32m    124\u001b[39m     questions = extract_response(qs).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m#print(questions)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\BOOOKSum\\utils.py:70\u001b[39m, in \u001b[36mLlmCompleter.get_completion\u001b[39m\u001b[34m(self, query, system, examples, choices, rep_penalty, regex_pattern, max_tokens, use_beam_search, beam_width, answer_prefix)\u001b[39m\n\u001b[32m     53\u001b[39m     beam_width = \u001b[38;5;28mmax\u001b[39m(\u001b[32m3\u001b[39m, beam_width)\n\u001b[32m     54\u001b[39m completion = \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(\n\u001b[32m     55\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.path,\n\u001b[32m     56\u001b[39m     messages=msgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m completion\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:1661\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1620\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1621\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1622\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1658\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1659\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   1660\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1662\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1663\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1664\u001b[39m             {\n\u001b[32m   1665\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   1666\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1667\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   1668\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   1669\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   1670\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   1671\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   1672\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   1673\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   1674\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   1675\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1676\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   1677\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   1678\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1679\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   1680\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   1681\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   1682\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   1683\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1684\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   1685\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1686\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1687\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   1688\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1689\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1690\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1691\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   1692\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1693\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1694\u001b[39m             },\n\u001b[32m   1695\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m   1696\u001b[39m         ),\n\u001b[32m   1697\u001b[39m         options=make_request_options(\n\u001b[32m   1698\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1699\u001b[39m         ),\n\u001b[32m   1700\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   1701\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1702\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   1703\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1843\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1829\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1830\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1831\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1838\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1839\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1840\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1841\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1842\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1537\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1535\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1538\u001b[39m     cast_to=cast_to,\n\u001b[32m   1539\u001b[39m     options=options,\n\u001b[32m   1540\u001b[39m     stream=stream,\n\u001b[32m   1541\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1542\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1543\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\openai\\_base_client.py:1576\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1573\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.custom_auth\n\u001b[32m   1575\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1577\u001b[39m         request,\n\u001b[32m   1578\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1579\u001b[39m         **kwargs,\n\u001b[32m   1580\u001b[39m     )\n\u001b[32m   1581\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1582\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpx\\_transports\\default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_async\\http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1249\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\WIKIbench\\Lib\\asyncio\\locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from utils import chunk_text\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "final_result = []\n",
    "total_count = 0\n",
    "\n",
    "with tqdm(total = 100, desc='Summarizing') as pbar:\n",
    "    for item in bench.collection:\n",
    "        if total_count == 100:\n",
    "            print('DONE')\n",
    "            break\n",
    "            \n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                \n",
    "                tmp = {}\n",
    "                text = '\\n'.join(item['text'])\n",
    "                if len(text) > 800000:\n",
    "                    break\n",
    "                chunks = chunk_text(text)\n",
    "                s = await bench.blueprint.run(chunks, initial_word_limit=500, mode='default')\n",
    "                tmp['blueprint'] = s\n",
    "                pbar.set_postfix({\n",
    "                'blueprint': len(s),\n",
    "                })\n",
    "                \n",
    "                s = await bench.blueprint.run(chunks, initial_word_limit=500, mode='cluster')\n",
    "                tmp['blueprint_cluster'] = s\n",
    "                pbar.set_postfix({\n",
    "                'blueprint_cluster': len(s),\n",
    "                })\n",
    "                \n",
    "                s = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=False)\n",
    "                tmp['hierarchical'] = s\n",
    "                pbar.set_postfix({\n",
    "                'hierarchical': len(s),\n",
    "                })\n",
    "                \n",
    "                s = await bench.hierarchical.run(chunks, initial_word_limit=500, filtered=True)\n",
    "                tmp['hierarchical_filtered'] = s\n",
    "                pbar.set_postfix({\n",
    "                'hierarchical_filtered': len(s),\n",
    "                })\n",
    "                \n",
    "                final_result.append(\n",
    "                    {'title': item['title'], \n",
    "                     'author': item['author'], \n",
    "                     'authors': item['authors'], \n",
    "                     'annotations': tmp, \n",
    "                     'gold_annotation': \n",
    "                     item['annotation']}\n",
    "                )\n",
    "                total_count += 1\n",
    "                pbar.update(1)\n",
    "                break\n",
    "                \n",
    "            except (KeyboardInterrupt, asyncio.CancelledError):\n",
    "                raise\n",
    "                \n",
    "            except:\n",
    "                time.sleep(10)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60664\n",
      "60300\n",
      "635480\n",
      "870892\n",
      "17631\n",
      "12383\n",
      "24864\n",
      "24373\n",
      "10304\n",
      "18493\n",
      "25151\n",
      "47887\n",
      "122565\n",
      "44215\n",
      "28251\n",
      "17376\n",
      "16603\n",
      "16872\n",
      "7772\n",
      "17818\n",
      "11862\n",
      "11645\n",
      "11566\n",
      "18891\n",
      "3825\n",
      "7398\n",
      "9984\n",
      "8546\n",
      "9307\n",
      "335612\n",
      "9789\n",
      "5568\n",
      "3927\n",
      "7307\n",
      "25253\n",
      "4284\n",
      "6688\n",
      "60183\n",
      "25868\n",
      "117459\n",
      "483063\n",
      "9877\n",
      "9501\n",
      "29465\n",
      "411489\n",
      "7646\n",
      "83778\n",
      "1537853\n",
      "18316\n",
      "37593\n",
      "43823\n",
      "8217\n",
      "192441\n",
      "932304\n",
      "11062\n",
      "21920\n",
      "24449\n",
      "102817\n",
      "135059\n",
      "82998\n",
      "524475\n",
      "705631\n",
      "63766\n",
      "49239\n",
      "66981\n",
      "121975\n",
      "698463\n",
      "52643\n",
      "133309\n",
      "14779\n",
      "18277\n",
      "37638\n",
      "157543\n",
      "17064\n",
      "26297\n",
      "3840\n",
      "56724\n",
      "253915\n",
      "81049\n",
      "53921\n",
      "24017\n",
      "55174\n",
      "30742\n",
      "51644\n",
      "35035\n",
      "59239\n",
      "7965\n",
      "18731\n",
      "286982\n",
      "365070\n",
      "592985\n",
      "345999\n",
      "291264\n",
      "351626\n",
      "363080\n",
      "313399\n",
      "334280\n",
      "328262\n",
      "169556\n",
      "24202\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(bench.collection[:100]):\n",
    "    print(len('\\n'.join(item['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Идёт суд над босым и худым мужичком Денисом Григорьевым. Его обвиняют в отвинчивании гайки, которой рельсы крепятся к шпалам. Мужичок этого не отрицает, но своей вины не видит. Следователь выясняет, что Денис, как и другие климовские мужики, откручивает гайки для того, чтобы делать из них грузила. Подсудимый искренне не понимает, что такое отвинчивание может привести к аварии поезда и к гибели людей. Следователь отправляет злоумышленника в тюрьму, но тот по прежнему не понимает, что он такого сделал.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.collection[36]['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('llama_final.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_result, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c7064d98a6e46b480c3ade68cc8a3c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d248f79c4cf743e99d35f1af67b15ac7",
      "max": 4836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_757c85b80ca843f08e854ce85650e583",
      "value": 4836
     }
    },
    "16ec219f49aa4847ac8ad49359822eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2026744200244e6aa47a44446ec8a85",
      "placeholder": "​",
      "style": "IPY_MODEL_d36eec2920c3417ba4c8615e2290f49c",
      "value": "README.md: 100%"
     }
    },
    "3e7f31fa3ca247a18b1e3818f6288ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5760f673228a4cf7903d74074a838cc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a7899e5f28c463fa27099a5ea98218d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c47b56edffc4c418ff8ea904697a592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "757c85b80ca843f08e854ce85650e583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88c42a190e6946bd8637a43798ba8c35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e7fb2300a7d44ab84b791feeeb191fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0af4fa6d2f04455af7e7d91cd698a86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a728f73524524bb5942b2cea78eb2345": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a7899e5f28c463fa27099a5ea98218d",
      "placeholder": "​",
      "style": "IPY_MODEL_a0af4fa6d2f04455af7e7d91cd698a86",
      "value": " 1.83k/1.83k [00:00&lt;00:00, 29.5kB/s]"
     }
    },
    "a7857ee187e948d0850a28dd6c7f2242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f22555acc90f463b98f5d47e0a70ba5e",
      "placeholder": "​",
      "style": "IPY_MODEL_88c42a190e6946bd8637a43798ba8c35",
      "value": "librusec_full.py: 100%"
     }
    },
    "a8d4d2c9b0e740fa8e553d587db6592f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae46aa6d346b4fb0adc717855cc84275": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2026744200244e6aa47a44446ec8a85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3f7a153059c461fa83eb81290af2ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7857ee187e948d0850a28dd6c7f2242",
       "IPY_MODEL_0c7064d98a6e46b480c3ade68cc8a3c9",
       "IPY_MODEL_c2b6c403021948598fa7162df4937003"
      ],
      "layout": "IPY_MODEL_9e7fb2300a7d44ab84b791feeeb191fa"
     }
    },
    "c2b6c403021948598fa7162df4937003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5760f673228a4cf7903d74074a838cc1",
      "placeholder": "​",
      "style": "IPY_MODEL_6c47b56edffc4c418ff8ea904697a592",
      "value": " 4.84k/4.84k [00:00&lt;00:00, 76.0kB/s]"
     }
    },
    "d248f79c4cf743e99d35f1af67b15ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36eec2920c3417ba4c8615e2290f49c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e712b923e6614115b54c6b4d36311854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16ec219f49aa4847ac8ad49359822eee",
       "IPY_MODEL_e9cb9d5b314642d7b4a8260978e8d57f",
       "IPY_MODEL_a728f73524524bb5942b2cea78eb2345"
      ],
      "layout": "IPY_MODEL_a8d4d2c9b0e740fa8e553d587db6592f"
     }
    },
    "e9cb9d5b314642d7b4a8260978e8d57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae46aa6d346b4fb0adc717855cc84275",
      "max": 1835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e7f31fa3ca247a18b1e3818f6288ae4",
      "value": 1835
     }
    },
    "f22555acc90f463b98f5d47e0a70ba5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
